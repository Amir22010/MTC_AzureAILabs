{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy TensorFlow model to ACI\n",
    "\n",
    "\n",
    "In the previous lab, we used `Hyperdrive` to tune FCNN top model. The model was registered in Model Registry.\n",
    "\n",
    "Now, we are ready to deploy the model.\n",
    "\n",
    "The model can be deployed to a variety of target runtimes, including:\n",
    "- Azure Container Instance\n",
    "- Azure Kubernetes Service\n",
    "- IoT Edge\n",
    "- FPGA\n",
    "\n",
    "\n",
    "In this lab, we will deploy the model as a web service in Azure Container Instance.\n",
    "\n",
    "![AML Arch](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/amlarch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.2\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /data/home/demouser/notebooks/MTC_AzureAILabs/ML-DeepLearningOnAzure/aml_config/config.json\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy as web service\n",
    "\n",
    "To build the correct environment for ACI, provide the following:\n",
    "* A scoring script that invokes the model\n",
    "* An environment file to show what packages need to be installed\n",
    "* A configuration file to build the ACI\n",
    "* The model you trained before\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create scoring script\n",
    "\n",
    "Create the scoring script, called score.py, used by the web service call to invoke the model.\n",
    "\n",
    "You must include two required functions in the scoring script:\n",
    "* The `init()` function, which loads the model into a global object. This function is run only once when the Docker container is started. \n",
    "\n",
    "* The `run(input_data)` function uses the model to predict a value based on the input data. Inputs and outputs to the run typically use JSON for serialization and de-serialization, but other formats can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "import azureml.contrib.brainwave.models.utils as utils\n",
    "from azureml.contrib.brainwave.models import QuantizedResnet50\n",
    "\n",
    "def init():\n",
    "    # Instantiate ResNet50 featurizer\n",
    "    global featurizer\n",
    "    \n",
    "    # Create ResNet50 \n",
    "    model_path = os.path.expanduser('~/models')\n",
    "    featurizer = QuantizedResnet50(model_path, is_frozen=True)\n",
    "\n",
    "    # Load the pretrained top\n",
    "    global model\n",
    "    # retreive the path to the model file using the model name\n",
    "    model_path = Model.get_model_path(model_name = '<<modelid>>')\n",
    "    #model = load_model(model_path)\n",
    "    print(model_path)\n",
    "  \n",
    "\n",
    "def run(raw_data):\n",
    "    try:\n",
    "        # convert json to numpy array\n",
    "        images = np.array(json.loads(raw_data)['data'])\n",
    "        # normalize as required by ResNet50\n",
    "        \n",
    "        predictions = str(images.shape)\n",
    "        \n",
    "        # Call the top\n",
    "        # predictions = model.predict(features)\n",
    "        # Add string labels\n",
    "        #labels = [\"Barren\",\n",
    "        #          \"Cultivated\",\n",
    "        #          \"Developed\",\n",
    "        #          \"Forest\",\n",
    "        #          \"Herbaceous\",\n",
    "        #          \"Shrub\"]\n",
    "        \n",
    "        # Get string labels for predictions\n",
    "        #string_predictions = [labels[pred] for pred in predictions]\n",
    "        \n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})\n",
    "    \n",
    "    # Return both numeric and string predictions\n",
    "    # return json.dumps({\"predictions\": predictions.tolist(), \"labels\": string_predictions})\n",
    "    return json.dumps({\"predictions\": predictions})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substitute the actual model ID in the script file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model_name = 'aerial-classifier-brainwave'\n",
    "model = Model(ws, name=model_name)\n",
    "script_file_name = 'score.py'\n",
    "\n",
    "with open(script_file_name, 'r') as cefr:\n",
    "    content = cefr.read()\n",
    "    \n",
    "with open(script_file_name, 'w') as cefw:\n",
    "    cefw.write(content.replace('<<modelid>>', model.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelNotFoundException",
     "evalue": "Model not found in cache or in root at ./aerial-classifier-brainwave. For more info,set logging level to DEBUG.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelNotFoundException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b8f8420910b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/azureml/core/model.py\u001b[0m in \u001b[0;36mget_model_path\u001b[0;34m(model_name, version, _workspace)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_model_path_remote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactive_workspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_model_path_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/azureml/core/model.py\u001b[0m in \u001b[0;36m_get_model_path_local\u001b[0;34m(model_name, version)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;31m# Probing azureml-models/<name>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_model_path_local_from_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Probing azureml-models/<name> exists, probing version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/site-packages/azureml/core/model.py\u001b[0m in \u001b[0;36m_get_model_path_local_from_root\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcandidate_model_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         raise ModelNotFoundException(\"Model not found in cache or in root at ./{}. For more info,\"\n\u001b[0;32m--> 383\u001b[0;31m                                      \"set logging level to DEBUG.\".format(candidate_model_path))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelNotFoundException\u001b[0m: Model not found in cache or in root at ./aerial-classifier-brainwave. For more info,set logging level to DEBUG."
     ]
    }
   ],
   "source": [
    "model.get_model_path(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the updated script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"score.py\",\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Conda dependencies environment file.\n",
    "\n",
    "Next, create an environment file that specifies the script's package dependencies. This file is used to ensure that all of those dependencies are installed in the Docker image. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "mycondaenv = CondaDependencies.create(pip_packages=[\n",
    "                'h5py', \n",
    "                'pillow', \n",
    "                'tqdm', \n",
    "                'azureml-sdk[contrib]', \n",
    "                'scikit-learn', \n",
    "                'tensorflow==1.10'])\n",
    "\n",
    "with open(\"mydeployenv.yml\",\"w\") as f:\n",
    "    f.write(mycondaenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the content of 'yml' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mydeployenv.yml\",\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create docker image for deployment\n",
    "\n",
    "To create a Container Image, you need four things: the model metadata (as retrieved from Model Registry), the scoring script file, the runtime configuration (defining whether Python or PySpark should be used) and the Conda Dependencies file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_model_path(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage, Image\n",
    "\n",
    "# configure the image\n",
    "image_config = ContainerImage.image_configuration(execution_script=\"score.py\", \n",
    "                                                  runtime=\"python\", \n",
    "                                                  conda_file=\"mydeployenv.yml\",\n",
    "                                                  description=\"Image for aerial classifier\",\n",
    "                                                  tags={\"Classifier\": \"FCNN\"})\n",
    "\n",
    "image = Image.create(name = \"aerial-classifier-image\",\n",
    "                     # this is the model object \n",
    "                     models = [model],\n",
    "                     image_config = image_config, \n",
    "                     workspace = ws)\n",
    "\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ACI configuration\n",
    "\n",
    "Create a deployment configuration file and specify the number of CPUs and gigabyte of RAM needed for your ACI container. The default is 1 core and 1 gigabyte of RAM. Since we are using ResNet50 featurizer we are CPU bound.  In this lab we will use the defaults but you should always go through the proper performance plannig exercise to find the right configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={\"data\": \"aerial\",  \"method\" : \"classifier\"}, \n",
    "                                               description='Predict aerial images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy in ACI\n",
    "\n",
    "Deploy the image as a web service in Azure Container Instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "aci_service_name = 'aerial-classifier-svc'\n",
    "print(aci_service_name)\n",
    "aci_service = Webservice.deploy_from_image(deployment_config = aciconfig,\n",
    "                                           image = image,\n",
    "                                           name = aci_service_name,\n",
    "                                           workspace = ws)\n",
    "aci_service.wait_for_deployment(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To troubleshoot any deployment issues you can retrieve deployment logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aci_service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the scoring web service's HTTP endpoint, which accepts REST client calls. This endpoint can be shared with anyone who wants to test the web service or integrate it into an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aci_service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test deployed service\n",
    "\n",
    "You will now test the deployed model with 3 test images.  \n",
    " \n",
    "First, download sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "mkdir samples\n",
    "cd samples\n",
    "wget -nv https://azureailabs.blob.core.windows.net/aerialsamples/barren-1.png\n",
    "wget -nv https://azureailabs.blob.core.windows.net/aerialsamples/cultivated-1.png\n",
    "wget -nv https://azureailabs.blob.core.windows.net/aerialsamples/developed-1.png\n",
    "ls -l\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define utility function that wraps loading images and invoking the service. The function takes as an input a list of pathnames to images. It loads and converts the binary images into a JSON array and invokes the service passing the JSON payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def score(pathnames, service):\n",
    "    images = []\n",
    "    for pathname in pathnames:\n",
    "        img = Image.open(pathname)\n",
    "        img = np.asarray(img).tolist()\n",
    "        images.append(img)\n",
    "    images = json.dumps({\"data\": images})\n",
    "    images = bytes(images, encoding='utf8')\n",
    "    results = json.loads(service.run(input_data=images))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aci_service = Webservice(workspace=ws, name='aerial-automl-svc')\n",
    "\n",
    "pathnames = ['samples/barren-1.png', 'samples/developed-1.png', 'samples/cultivated-1.png']\n",
    "\n",
    "results = score(pathnames, aci_service)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up resources\n",
    "\n",
    "Delete the ACI service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aci_service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
