{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Feature Engineering\n",
    "In this lab we will develop and run a Python script that pre-processes training and validation images into a set of powerful features - refered to in the lab as bottleneck features.\n",
    "\n",
    "To create bottleneck features we will utilize a pre-trained Deep Learning network that was trained on a general computer vision domain. \n",
    "\n",
    "As explained by your instructor this approach is called Transfer Learning. Transfer Learning is a powerful Machine Learning technique that is based on an observation that the knowledge gained while solving one problem can be applied to a different (but related problem).\n",
    "\n",
    "In the context of an image classification task, a DNN trained on one visual domain can accelerate learing in another visual domain. Although, our pre-trained network does not know how to classify aerial land plot images, it knows enough about representing image concepts that if we use it to pre-process aerial images, the extracted image features can be used to effectively train a relatively simple classifier on a **limited number** of samples.\n",
    "\n",
    "The below diagram represents the architecture of our solution.\n",
    "\n",
    "![Transfer Learning](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/tlcl.png)\n",
    "\n",
    "We will use **ResNet50** trained on **imagenet** dataset to extract features. We will occasionally refer to this component of the solution as a featurizer. The output of the featurizer is a vector of 2048 floating point numbers, each representing a feature extracted from an image. \n",
    "\n",
    "We will then use extracted features to train an scikit-learn classifier. (next lab).\n",
    "\n",
    "The Python script processes an input image dataset into an output bottleneck feature set. The script expects the images to be organized in the below folder structure:\n",
    "```\n",
    "train/\n",
    "   Barren/\n",
    "   Cultivated/\n",
    "   Developed/\n",
    "   Forest/\n",
    "   Herbaceous/\n",
    "   Shrub/\n",
    "valid/\n",
    "   Barren/\n",
    "   Cultivated/\n",
    "   Developed/\n",
    "   Forest/\n",
    "   Herbaceous/\n",
    "   Shrub/\n",
    "```\n",
    "\n",
    "The location of the input dataset and the location where to save the output dataset are passed to the script as command line parameters. The output dataset will be stored in a binary HDF5 data format used commonly in Machine Learning and High Performance Computing solutions.\n",
    "\n",
    "The script is designed to work with a large number of images. As such it does not load all input images to memory at once. Instead it utilizes custom Python generator class - `ImageGenerator` to feed the featurizer. The class yields batches of images - as Numpy arrays - preprocessed to the format required by **ResNet50**. \n",
    "\n",
    "We will not attempt to run the script on a full dataset in a local environment. It is very computationally intensive and unless you run it in an evironment equipped with a powerful GPU it would be very slow. \n",
    "\n",
    "However, we will demonstrate how to run the script locally using the same small development dataset we used in the previous lab. Running the script locally under the control of Azure ML is very usefull during script development and debugging.\n",
    "\n",
    "To process the full dataset we will send the debugged script to a remote Azure GPU VM.\n",
    "\n",
    "Your instructor will dive into the code in the script and explain key snippets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data pre-processing script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a folder to hold the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Jupyter `%%writefile` magic to write the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./script/extract.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/extract.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import resnet50\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# This is a generator that yields batches of preprocessed images\n",
    "class ImageGenerator(tf.keras.utils.Sequence):    \n",
    "    \n",
    "    def __init__(self, img_dir, preprocess_fn=None, batch_size=64):\n",
    "        \n",
    "        # Create the dictionary that maps class names into numeric labels \n",
    "        folders = os.listdir(img_dir)\n",
    "        folders.sort()\n",
    "        indexes = range(len(folders))\n",
    "        label_map = {key: value for (key, value) in zip(folders, indexes)}\n",
    "        self.num_classes = len(label_map)\n",
    "        \n",
    "        # Create a list of all images in a root folder with associated numeric labels\n",
    "        labeled_image_list = [(os.path.join(img_dir, folder, image), label_map[folder]) \n",
    "                              for folder in folders \n",
    "                              for image in os.listdir(os.path.join(img_dir, folder))\n",
    "                              ]\n",
    "        # Shuffle the list\n",
    "        random.shuffle(labeled_image_list)\n",
    "        # Set image list and associated label list\n",
    "        self.image_list, self.label_list = zip(*labeled_image_list) \n",
    "        # Set batch size\n",
    "        self.batch_size = batch_size\n",
    "       \n",
    "        # Set the pre-processing function passed as a parameter\n",
    "        self.preprocess_fn = preprocess_fn\n",
    "        \n",
    "        # Set number of batches\n",
    "        self.n_batches = len(self.image_list) // self.batch_size\n",
    "        if len(self.image_list) % self.batch_size > 0:\n",
    "            self.n_batches += 1\n",
    "            \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.n_batches\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        pathnames = self.image_list[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        images = self.__load_images(pathnames)\n",
    "        \n",
    "        return images\n",
    "    \n",
    "    # Load a set of images passed as a parameter into a NumPy array\n",
    "    def __load_images(self, pathnames):\n",
    "        images = []\n",
    "        for pathname in pathnames:\n",
    "            img = image.load_img(pathname, target_size=(224,224,3))\n",
    "            img = image.img_to_array(img)\n",
    "            images.append(img)\n",
    "        images = np.asarray(images)\n",
    "        if self.preprocess_fn != None:\n",
    "            images = self.preprocess_fn(images)   \n",
    "        \n",
    "        return images\n",
    "    \n",
    "    # Return labels in one-hot encoding\n",
    "    def get_labels(self):\n",
    "        \n",
    "        #return to_categorical(np.asarray(self.label_list), self.num_classes)\n",
    "        return np.asarray(self.label_list)\n",
    "\n",
    "\n",
    "def create_bottleneck_features():\n",
    "    # Configure input directories\n",
    "    train_images_dir = os.path.join(FLAGS.input_data_dir, 'train')\n",
    "    #valid_images_dir = os.path.join(FLAGS.input_data_dir, 'valid')\n",
    "\n",
    "    train_generator = ImageGenerator(train_images_dir, resnet50.preprocess_input)\n",
    "    #valid_generator = ImageGenerator(valid_images_dir, resnet50.preprocess_input)\n",
    "    \n",
    "    featurizer = resnet50.ResNet50(\n",
    "                weights = 'imagenet', \n",
    "                input_shape=(224,224,3), \n",
    "                include_top = False,\n",
    "                pooling = 'avg')\n",
    "    \n",
    "\n",
    "    # Generate training bottleneck features\n",
    "    print(\"Generating training bottleneck features\")\n",
    "    features = featurizer.predict_generator(train_generator, verbose=1)\n",
    "    labels = train_generator.get_labels()\n",
    "    \n",
    "    # Save training dataset to HDF5 file\n",
    "    filename = FLAGS.training_file_name\n",
    "    output_file = os.path.join(FLAGS.output_data_dir, filename)\n",
    "    print(\"Saving training features to {}\".format(output_file))\n",
    "    print(\"   Training features: \", features.shape)\n",
    "    print(\"   Training labels: \", labels.shape)\n",
    "    with h5py.File(output_file, \"w\") as hfile:\n",
    "        features_dset = hfile.create_dataset('features', data=features)\n",
    "        labels_dset = hfile.create_dataset('labels', data=labels)\n",
    "\n",
    "     # Generate validation bottleneck features\n",
    "    #print(\"Generating validation bottleneck features\")\n",
    "    #features = featurizer.predict_generator(valid_generator, verbose=1)\n",
    "    #labels = valid_generator.get_labels()\n",
    "    \n",
    "    # Save validation dataset to HDF5 file\n",
    "    #filename = FLAGS.validation_file_name\n",
    "    #output_file = os.path.join(FLAGS.output_data_dir, filename)\n",
    "    #print(\"Saving validation features to {}\".format(output_file))\n",
    "    #print(\"   Validation features: \", features.shape)\n",
    "    #print(\"   Validation labels: \", labels.shape)\n",
    "    #with h5py.File(output_file, \"w\") as hfile:\n",
    "    #    features_dset = hfile.create_dataset('features', data=features)\n",
    "    #    labels_dset = hfile.create_dataset('labels', data=labels)\n",
    "    \n",
    "    #print(\"Done\")\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "# Default global parameters\n",
    "tf.app.flags.DEFINE_integer('batch_size', 64, \"Number of images per batch\")\n",
    "tf.app.flags.DEFINE_string('input_data_dir', 'aerialtiny', \"Folder with training and validation images\")\n",
    "tf.app.flags.DEFINE_string('output_data_dir', 'bottleneck', \"A folder for saving bottleneck features\")\n",
    "tf.app.flags.DEFINE_string('training_file_name', 'aerial_bottleneck_train_resnet50.h5', \"Name of output training file\")\n",
    "#tf.app.flags.DEFINE_string('validation_file_name', 'aerial_bottleneck_valid_vgg16.h5', \"Name of output validation file\")\n",
    "\n",
    "def main(argv=None):\n",
    "    print(\"Starting\")\n",
    "    print(\"Reading training data from:\", FLAGS.input_data_dir)\n",
    "    print(\"Output bottleneck files will be saved to:\", FLAGS.output_data_dir)\n",
    "\n",
    "    os.makedirs(FLAGS.output_data_dir, exist_ok=True)\n",
    "\n",
    "    create_bottleneck_features()\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the script locally\n",
    "\n",
    "As noted in the introduction, we will first run the script locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize AML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /home/demouser/repos/MTC_AzureAILabs/DataScienceTrack/01-aml-walkthrough-sklearn/aml_config/config.json\n",
      "jkamllab\n",
      "jkamllab\n",
      "eastus2\n",
      "952a710c-8d9c-40c1-9fec-f752138cc0b3\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config('../aml_config/config.json')\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an Experiment\n",
    "We will track local runs in a dedicated Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "experiment_name = 'aerial-feature-engineering'\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Run environment\n",
    "We will use a user-managed run, which means we assume that all the necessary packages are already available in the Python environment selected to run the script. In our case this is true, as we pre-installed all the dependencies during the lab setup. Alternatively, you can execute a local run in system-managed environment. In that case AML would build a new conda environment and execute the script in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "run_config = RunConfiguration()\n",
    "run_config.environment.python.user_managed_dependencies = True\n",
    "#run_config.environment.python.interpreter_path = '/anaconda/envs/py36/bin/python' # AML env\n",
    "run_config.environment.python.interpreter_path = '/home/demouser/anaconda3/envs/aml/bin/python'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the script. Note that we need to supply an absolute path to the folder with training and validation images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>aerial-feature-engineering</td><td>aerial-feature-engineering_1541173516_04b87551</td><td>azureml.scriptrun</td><td>Running</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/952a710c-8d9c-40c1-9fec-f752138cc0b3/resourceGroups/jkamllab/providers/Microsoft.MachineLearningServices/workspaces/jkamllab/experiments/aerial-feature-engineering/runs/aerial-feature-engineering_1541173516_04b87551\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: aerial-feature-engineering,\n",
       "Id: aerial-feature-engineering_1541173516_04b87551,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Running)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "src = ScriptRunConfig(\n",
    "    source_directory='./script',\n",
    "    script='extract.py',\n",
    "    run_config=run_config,\n",
    "    arguments=['--input_data_dir', '/tmp/aerialtiny',\n",
    "               '--output_data_dir', 'bottleneck'] )\n",
    "\n",
    "tags = {\"Compute target\": \"Local\", \"DNN\": \"ResNet50\"}\n",
    "run = exp.submit(src, tags=tags)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Block to wait till run finishes and stream the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: aerial-feature-engineering_1541173516_04b87551\n",
      "\n",
      "Streaming azureml-logs/60_control_log.txt\n",
      "=========================================\n",
      "\n",
      "Streaming log file azureml-logs/60_control_log.txt\n",
      "Running: ['/home/demouser/anaconda3/envs/aml/bin/python', 'azureml-setup/run_script.py', '/home/demouser/anaconda3/envs/aml/bin/python', 'azureml-setup/context_manager_injector.py', '-i', 'ProjectPythonPath:context_managers.ProjectPythonPath', '-i', 'OutputCollection:context_managers.RunHistory', 'extract.py', '--input_data_dir', '/tmp/aerialtiny', '--output_data_dir', 'bottleneck']\n",
      "Logging experiment running status in history service.\n",
      "Streaming log file azureml-logs/80_driver_log.txt\n",
      "\n",
      "Streaming azureml-logs/80_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Starting\n",
      "Reading training data from: /tmp/aerialtiny\n",
      "Output bottleneck files will be saved to: bottleneck\n",
      "2018-11-02 15:45:33.148338: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2018-11-02 15:45:36.669586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: d914:00:00.0\n",
      "totalMemory: 15.78GiB freeMemory: 15.37GiB\n",
      "2018-11-02 15:45:36.852553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 1 with properties: \n",
      "name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: daf4:00:00.0\n",
      "totalMemory: 15.78GiB freeMemory: 15.37GiB\n",
      "2018-11-02 15:45:36.856789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0, 1\n",
      "2018-11-02 15:45:46.508585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-11-02 15:45:46.508638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 1 \n",
      "2018-11-02 15:45:46.508647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N N \n",
      "2018-11-02 15:45:46.508652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 1:   N N \n",
      "2018-11-02 15:45:46.509299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14871 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-16GB, pci bus id: d914:00:00.0, compute capability: 7.0)\n",
      "2018-11-02 15:45:46.665460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 14871 MB memory) -> physical GPU (device: 1, name: Tesla V100-PCIE-16GB, pci bus id: daf4:00:00.0, compute capability: 7.0)\n",
      "Generating training bottleneck features\n",
      "\n",
      " 1/17 [>.............................] - ETA: 2:\n",
      " 2/17 [==>...........................] - ETA: 1:\n",
      " 3/17 [====>.........................] - ETA: 37s\n",
      " 4/17 [======>.......................] - ETA: 26s\n",
      " 5/17 [=======>......................] - ETA: 20\n",
      " 6/17 [=========>....................] - ETA: 15\n",
      " 7/17 [===========>..................] - ETA: 12\n",
      " 8/17 [=============>................] - ETA: 9\n",
      " 9/17 [==============>...............] - ETA: \n",
      "10/17 [================>.............] - ETA: \n",
      "11/17 [==================>...........] - ETA: \n",
      "12/17 [====================>.........] - ETA: \n",
      "13/17 [=====================>........] - ETA: \n",
      "14/17 [=======================>......] - ETA: \n",
      "15/17 [=========================>....] - ETA: \n",
      "16/17 [===========================>..] - ETA: \n",
      "17/17 [==============================] - 10s 580ms/step\n",
      "Saving training features to bottleneck/aerial_bottleneck_train_resnet50.h5\n",
      "   Training features:  (1060, 2048)\n",
      "   Training labels:  (1060,)\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Logging experiment finalizing status in history service\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: aerial-feature-engineering_1541173516_04b87551\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'aerial-feature-engineering_1541173516_04b87551',\n",
       " 'target': 'local',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2018-11-02T15:45:16.885403Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'ContentSnapshotId': '23163768-4467-4dec-84a4-3aa706d29dfa'},\n",
       " 'runDefinition': {'Script': 'extract.py',\n",
       "  'Arguments': ['--input_data_dir',\n",
       "   '/tmp/aerialtiny',\n",
       "   '--output_data_dir',\n",
       "   'bottleneck'],\n",
       "  'SourceDirectoryDataStore': None,\n",
       "  'Framework': 0,\n",
       "  'Target': 'local',\n",
       "  'DataReferences': {},\n",
       "  'JobName': None,\n",
       "  'AutoPrepareEnvironment': True,\n",
       "  'MaxRunDurationSeconds': None,\n",
       "  'Environment': {'Python': {'InterpreterPath': '/home/demouser/anaconda3/envs/aml/bin/python',\n",
       "    'UserManagedDependencies': True,\n",
       "    'CondaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults']}]},\n",
       "    'CondaDependenciesFile': None},\n",
       "   'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base:0.1.4',\n",
       "    'Enabled': False,\n",
       "    'SharedVolumes': True,\n",
       "    'GpuSupport': False,\n",
       "    'Arguments': [],\n",
       "    'BaseImageRegistry': {'Address': None,\n",
       "     'Username': None,\n",
       "     'Password': None}},\n",
       "   'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'],\n",
       "    'Packages': [{'Group': 'com.microsoft.ml.spark',\n",
       "      'Artifact': 'mmlspark_2.11',\n",
       "      'Version': '0.12'}],\n",
       "    'PrecachePackages': True}},\n",
       "  'History': {'OutputCollection': True},\n",
       "  'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'BatchAi': {'NodeCount': 1},\n",
       "  'AmlCompute': {'VmSize': None,\n",
       "   'VmPriority': None,\n",
       "   'Location': None,\n",
       "   'RetainCluster': False},\n",
       "  'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1},\n",
       "  'Mpi': {'ProcessCountPerNode': 1},\n",
       "  'Hdi': {'YarnDeployMode': 2},\n",
       "  'ContainerInstance': {'Region': None, 'CpuCores': 1, 'MemoryGb': 4},\n",
       "  'ExposedPorts': None,\n",
       "  'PrepareEnvironment': None},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://jkamllabstoragemzbunfox.blob.core.windows.net/azureml/ExperimentRun/aerial-feature-engineering_1541173516_04b87551/azureml-logs/60_control_log.txt?sv=2017-04-17&sr=b&sig=xAY5fgXwE3B55dsGmx0FbS6L1wanoo3rFaZVFLgCSb8%3D&st=2018-11-02T15%3A36%3A00Z&se=2018-11-02T23%3A46%3A00Z&sp=r',\n",
       "  'azureml-logs/80_driver_log.txt': 'https://jkamllabstoragemzbunfox.blob.core.windows.net/azureml/ExperimentRun/aerial-feature-engineering_1541173516_04b87551/azureml-logs/80_driver_log.txt?sv=2017-04-17&sr=b&sig=uk4FAOPKvVTvP8sWq5vJHaJj1ilPfQfyAL0SkLHfFU4%3D&st=2018-11-02T15%3A36%3A00Z&se=2018-11-02T23%3A46%3A00Z&sp=r',\n",
       "  'azureml-logs/azureml.log': 'https://jkamllabstoragemzbunfox.blob.core.windows.net/azureml/ExperimentRun/aerial-feature-engineering_1541173516_04b87551/azureml-logs/azureml.log?sv=2017-04-17&sr=b&sig=pzyAVE%2BVU%2F2Q%2B6WBj8JwcZGdbLYHKEIpmJABIYozJ%2Fw%3D&st=2018-11-02T15%3A36%3A00Z&se=2018-11-02T23%3A46%3A00Z&sp=r'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logs from the run have been pushed to AML Experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['azureml-logs/60_control_log.txt', 'azureml-logs/80_driver_log.txt', 'driver_log', 'azureml-logs/azureml.log']\n"
     ]
    }
   ],
   "source": [
    "print(run.get_file_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bottleneck files can be found in a local folder associated with the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: RUN_ID=aerial-feature-engineering_1541173516_04b87551\n"
     ]
    }
   ],
   "source": [
    "%env RUN_ID=$run.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aml_config\n",
      "assets\n",
      "azureml-logs\n",
      "azureml-setup\n",
      "bottleneck\n",
      "extract.py\n",
      "invocation.zip\n",
      "outputs\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "ls /tmp/azureml_runs/$RUN_ID/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the script on a remote GPU VM\n",
    "\n",
    "As you can see, even on a really small dataset the processing is very slow. In the next step, you will run the script on a full dataset using a remote GPU equipped VM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Azure DSVM as a compute target\n",
    "\n",
    "We will use *Standard_NC6* VM equipped with Tesla K80 GPU as a compute target. If the VM is already in the workspace this code uses it and skips the creation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating........................"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import DsvmCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "compute_target_name = 'gpudsvm'\n",
    "compute_target_type = 'Standard_NC6'\n",
    "\n",
    "try:\n",
    "    dsvm_compute = DsvmCompute(workspace=ws, name=compute_target_name)\n",
    "    print('Found existing DSVM:', dsvm_compute.name)\n",
    "except ComputeTargetException:\n",
    "    dsvm_config = DsvmCompute.provisioning_configuration(vm_size=compute_target_type)\n",
    "    dsvm_compute = DsvmCompute.create(ws, name=compute_target_name, provisioning_configuration=dsvm_config)\n",
    "    dsvm_compute.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Datastores \n",
    "The dataset we will use for training has been uploaded to a public Azure blob storage container. We will register this container as a datastore within our workspace. Before the data prep script runs, the datastore's content - training and validation images - will be copied to the local storage on DSVM.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "\n",
    "images_account = 'azureailabs'\n",
    "images_container = 'aerialmed'\n",
    "datastore_name = 'input_images'\n",
    "\n",
    "# Check if the datastore exists. If not create a new one\n",
    "try:\n",
    "    input_ds = Datastore.get(ws, datastore_name)\n",
    "    print('Found existing datastore for input images:', input_ds.name)\n",
    "except:\n",
    "    input_ds = Datastore.register_azure_blob_container(workspace=ws, datastore_name=datastore_name,\n",
    "                                            container_name=images_container,\n",
    "                                            account_name=images_account)\n",
    "    print('Creating new datastore for input images')\n",
    "\n",
    " \n",
    "   \n",
    "print(input_ds.name, input_ds.datastore_type, input_ds.account_name, input_ds.container_name)\n",
    "\n",
    "output_ds = ws.get_default_datastore()\n",
    "print(\"Using the default datastore for output: \")\n",
    "print(output_ds.name, output_ds.datastore_type, output_ds.account_name, output_ds.container_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start and monitor a remote run\n",
    "\n",
    "We will run a script in a new Conda environment that will be created automatically by AML and configured with the \n",
    "specified dependencies.\n",
    "\n",
    "The first run takes longer. The subsequent runs, as long as the script dependencies don't change, are much faster.\n",
    "\n",
    "You can check the progress of a running job in multiple ways. We will use AML Jupyter widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DataReferenceConfiguration\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "script_folder = 'script'\n",
    "script_name = 'extract.py'\n",
    "output_dir = 'bottleneck'\n",
    "input_dir = 'aerial'\n",
    "\n",
    "# create a new RunConfig object\n",
    "conda_run_config = RunConfiguration(framework=\"python\")\n",
    "\n",
    "# Set compute target to DSVM\n",
    "conda_run_config.target = dsvm_compute.name\n",
    "\n",
    "# specify CondaDependencies obj\n",
    "conda_packages = ['scikit-image', 'h5py', 'tensorflow-gpu']\n",
    "conda_run_config.environment.python.conda_dependencies = \\\n",
    "    CondaDependencies.create(conda_packages=conda_packages)\n",
    "    \n",
    "\n",
    "# configure data references\n",
    "input_dr = DataReferenceConfiguration(datastore_name=input_ds.name, \n",
    "                   path_on_compute=input_dir,                   \n",
    "                   mode='download', # download files from datastore to compute target\n",
    "                   overwrite=True)\n",
    "\n",
    "output_dr = DataReferenceConfiguration(datastore_name=output_ds.name, \n",
    "                   path_on_datastore=output_dir, \n",
    "                   path_on_compute=output_dir,\n",
    "                   mode='upload', # upload files from the compute to datastore\n",
    "                   overwrite=True)\n",
    "\n",
    "conda_run_config.data_references = {input_ds.name: input_dr, output_ds.name: output_dr}\n",
    "    \n",
    "\n",
    "# Specify command line arguments\n",
    "arguments = ['--input_data_dir', str(input_ds.as_download()),\n",
    "             '--output_data_dir', output_dir]\n",
    "\n",
    "\n",
    "# Configure the script \n",
    "src = ScriptRunConfig(source_directory=script_folder, \n",
    "                      script=script_name, \n",
    "                      run_config=conda_run_config, \n",
    "                      arguments=arguments \n",
    "                     ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the run and start RunDetails widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "\n",
    "tags = {\"Compute target\": \"DSVM\", \"DNN\": \"ResNet50\"}\n",
    "run = exp.submit(src)\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Block to wait till run finishes and stream the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the run AML copied the output bottleneck files to the default datastore. You can verify it using Azure Portal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up resources\n",
    "\n",
    "Before you move to the next step, you can delete the GPU VM. We will not need it anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsvm_compute.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step\n",
    "The run has completed. You are ready to move to the next part of the lab in which you are going to train a multinomial classification model using the bottleneck features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
