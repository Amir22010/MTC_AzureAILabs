{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Model Training\n",
    "In this section of the lab we will train a multinomial logistics regression model using the bottleneck features created in the previous part of the lab.\n",
    "\n",
    "\n",
    "![Transfer Learning](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/tllr.png)\n",
    "\n",
    "We will use `scikit-learn` to configure logistic regression and run training. \n",
    "\n",
    "We will run training on a remote CPU VM. `scikit-learn` cannot utilize GPU so we will not reuse the GPU VM created in the previous stage.\n",
    "\n",
    "![AML Arch](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/amlarch.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training script\n",
    "\n",
    "The trained model will be saved into the `./outputs` folder. This is one of the special folders in AML. The other one is the `./logs` folder. The content in these folders is automatically uploaded to the run history.\n",
    "\n",
    "The script uses AML `Run` object to track  **validation accuracy**. The metric is captured at the end of training.\n",
    "\n",
    "#### Create a folder to hold the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Jupyter `%%writefile` magic to write the script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./script/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/train.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import h5py\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "\n",
    "# Training regime\n",
    "def train_evaluate(run):\n",
    "   \n",
    "    print(\"Loading bottleneck features\")\n",
    "    train_file_name = os.path.join(args.data_folder, args.training_file_name)\n",
    "    valid_file_name = os.path.join(args.data_folder, args.validation_file_name)\n",
    "    \n",
    "    # Load bottleneck training features and labels\n",
    "    with h5py.File(train_file_name, \"r\") as hfile:\n",
    "        train_features = np.array(hfile.get('features'))\n",
    "        train_labels = np.array(hfile.get('labels'))\n",
    "        \n",
    "        \n",
    "    # Load bottleneck validation features and labels\n",
    "    with h5py.File(valid_file_name, \"r\") as hfile:\n",
    "        valid_features = np.array(hfile.get('features'))\n",
    "        valid_labels = np.array(hfile.get('labels'))\n",
    "        \n",
    "    # Conver one-hot labels to integers\n",
    "    y_train = np.argmax(train_labels, axis=1)\n",
    "    y_valid = np.argmax(valid_labels, axis=1)\n",
    "    \n",
    "    # Train logistics regresssion model\n",
    "    print(\"Starting training on\")\n",
    "    print(\"  Features:\", train_features.shape)\n",
    "    print(\"  Labels:\", y_train.shape)\n",
    "    clf = LogisticRegression(\n",
    "        C=1.0/args.reg, \n",
    "        multi_class='multinomial',\n",
    "        solver='lbfgs',\n",
    "        random_state=42)\n",
    "    clf.fit(train_features, y_train)\n",
    "    \n",
    "    \n",
    "    # Validate\n",
    "    print(\"Starting validation\")\n",
    "    y_hat = clf.predict(valid_features)\n",
    "    \n",
    "    # Calculate accuracy \n",
    "    acc = np.average(y_hat == y_valid)\n",
    "    print('Validatin accuracy is:', acc)\n",
    "    \n",
    "    # Log to AML Experiment\n",
    "    run.log('regularization_rate', np.float(args.reg))\n",
    "    run.log('validation_acc', np.float(acc))\n",
    "          \n",
    "    # Save the trained model to outp'uts which is a standard folder expected by AML\n",
    "    model_file = 'aerial_sklearn.pkl'\n",
    "    model_file = os.path.join('outputs', model_file)\n",
    "    print(\"Saving the model to: \", model_file)\n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    joblib.dump(value=clf, filename=model_file)\n",
    "    \n",
    "\n",
    "  \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(\"Training, evaluation worklfow\")\n",
    "\n",
    "    ### Model parameters\n",
    "    \n",
    "    parser.add_argument(\n",
    "        '--data-folder',\n",
    "        type=str,\n",
    "        default = './bottleneck',\n",
    "        help='Folder with bottleneck features and labels')\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--training-file-name',\n",
    "        type=str,\n",
    "        default = 'aerial_bottleneck_train.h5',\n",
    "        help='Training file name')\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--validation-file-name',\n",
    "        type=str,\n",
    "        default = 'aerial_bottleneck_valid.h5',\n",
    "        help='Validation file name')\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--regularization', \n",
    "        type=float, dest='reg', \n",
    "        default=0.01, \n",
    "        help='regularization rate')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # get hold of the current run\n",
    "    run = Run.get_submitted_run()\n",
    "    train_evaluate(run)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to AML workspace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /data/home/demouser/notebooks/MTC_AzureAILabs/DataScienceTrack/01-aml-walkthrough-sklearn/aml_config/config.json\n",
      "jkamllab\n",
      "jkamllab\n",
      "eastus2\n",
      "952a710c-8d9c-40c1-9fec-f752138cc0b3\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Experiment\n",
    "\n",
    "We will create a new experiment to manage training runs on a remote VM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'aerial-train-sklearn'\n",
    "\n",
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create  compute target\n",
    "\n",
    "We will create a new CPU VM to run the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating.............................\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import DsvmCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "compute_target_name = 'cpudsvm'\n",
    "compute_target_type = 'Standard_DS3_v2'\n",
    "\n",
    "try:\n",
    "    dsvm_compute = DsvmCompute(workspace=ws, name=compute_target_name)\n",
    "    print('Found existing DSVM:', dsvm_compute.name)\n",
    "except ComputeTargetException:\n",
    "    dsvm_config = DsvmCompute.provisioning_configuration(vm_size=compute_target_type)\n",
    "    dsvm_compute = DsvmCompute.create(ws, name=compute_target_name, provisioning_configuration=dsvm_config)\n",
    "    dsvm_compute.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure datastore\n",
    "\n",
    "The bottleneck files have been uploaded to the workspace's default datastore during the previous step. We will mount the store on the nodes of the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the default datastore for training data: \n",
      "workspacefilestore AzureFile jkamllab4248191217 azureml-filestore-d531180f-918f-440a-9cbc-968e4cc0ac1b\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Datastore\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "print(\"Using the default datastore for training data: \")\n",
    "print(ds.name, ds.datastore_type, ds.account_name, ds.container_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Conda run configuration\n",
    "\n",
    "This time we will not run the script in a Docker container. Instead, we will run it in a custom Conda environment within Data Science Virtual machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import DataReferenceConfiguration\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core import Run\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "\n",
    "# create a new RunConfig object\n",
    "conda_run_config = RunConfiguration(framework=\"python\")\n",
    "\n",
    "# Set compute target to our DSVM\n",
    "conda_run_config.target = dsvm_compute.name\n",
    "\n",
    "# set the data reference of the run configuration\n",
    "dr = DataReferenceConfiguration(datastore_name=ds.name, \n",
    "                   path_on_datastore='bottleneck', \n",
    "                   path_on_compute='bottleneck',\n",
    "                   mode='download', # download files from datastore to compute target\n",
    "                   overwrite=True)\n",
    "#conda_run_config.data_references = {ds.name: dr}\n",
    "\n",
    "# specify CondaDependencies obj\n",
    "conda_run_config.environment.python.conda_dependencies = CondaDependencies.create(conda_packages=['scikit-learn', 'h5py'])\n",
    "\n",
    "src = ScriptRunConfig(source_directory=script_folder, \n",
    "                      script='train.py', \n",
    "                      run_config=conda_run_config, \n",
    "                      # pass the datastore reference as a parameter to the training script\n",
    "                      arguments=['--data-folder', str(ds.as_download())] \n",
    "                     ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>aerial-train-sklearn</td><td>aerial-train-sklearn_1540955078313</td><td>azureml.scriptrun</td><td>Running</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/952a710c-8d9c-40c1-9fec-f752138cc0b3/resourceGroups/jkamllab/providers/Microsoft.MachineLearningServices/workspaces/jkamllab/experiments/aerial-train-sklearn/runs/aerial-train-sklearn_1540955078313\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: aerial-train-sklearn,\n",
       "Id: aerial-train-sklearn_1540955078313,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Running)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = {\"Run\": \"sklearn-logistic-regression\"}\n",
    "run = exp.submit(config=src, tags=tags)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitor the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3547d74ef941128a59aee240fb4ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRun()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'aerial-train-sklearn_1540954231561',\n",
       " 'target': 'dsvm',\n",
       " 'status': 'Failed',\n",
       " 'startTimeUtc': '2018-10-31T02:54:45.432034Z',\n",
       " 'endTimeUtc': '2018-10-31T02:54:49.523891Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'ContentSnapshotId': '09fa9fc8-3224-4a16-bf57-fc3c314cb0ce'},\n",
       " 'runDefinition': {'Script': 'train.py',\n",
       "  'Arguments': ['--data-folder', '$AZUREML_DATAREFERENCE_workspacefilestore'],\n",
       "  'SourceDirectoryDataStore': None,\n",
       "  'Framework': 0,\n",
       "  'Target': 'dsvm',\n",
       "  'DataReferences': {'workspacefilestore': {'DataStoreName': 'workspacefilestore',\n",
       "    'Mode': 'Download',\n",
       "    'PathOnDataStore': 'bottleneck',\n",
       "    'PathOnCompute': None,\n",
       "    'Overwrite': True}},\n",
       "  'JobName': None,\n",
       "  'AutoPrepareEnvironment': True,\n",
       "  'MaxRunDurationSeconds': None,\n",
       "  'Environment': {'Python': {'InterpreterPath': 'python',\n",
       "    'UserManagedDependencies': False,\n",
       "    'CondaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults==0.1.59']},\n",
       "      'scikit-learn',\n",
       "      'h5py']},\n",
       "    'CondaDependenciesFile': None},\n",
       "   'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base:0.1.3',\n",
       "    'Enabled': False,\n",
       "    'SharedVolumes': True,\n",
       "    'GpuSupport': False,\n",
       "    'Arguments': [],\n",
       "    'BaseImageRegistry': {'Address': None,\n",
       "     'Username': None,\n",
       "     'Password': None}},\n",
       "   'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'],\n",
       "    'Packages': [{'Group': 'com.microsoft.ml.spark',\n",
       "      'Artifact': 'mmlspark_2.11',\n",
       "      'Version': '0.12'}],\n",
       "    'PrecachePackages': True}},\n",
       "  'History': {'OutputCollection': True},\n",
       "  'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'BatchAi': {'NodeCount': 1},\n",
       "  'AmlCompute': {'VmSize': None,\n",
       "   'VmPriority': None,\n",
       "   'Location': None,\n",
       "   'RetainCluster': False},\n",
       "  'Tensorflow': {'WorkerCount': 2, 'ParameterServerCount': 1},\n",
       "  'Mpi': {'ProcessCountPerNode': 1},\n",
       "  'Hdi': {'YarnDeployMode': 2},\n",
       "  'ContainerInstance': {'Region': None, 'CpuCores': 1, 'MemoryGb': 4},\n",
       "  'ExposedPorts': None,\n",
       "  'PrepareEnvironment': None},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://jkamllab4248191217.blob.core.windows.net/azureml/ExperimentRun/aerial-train-sklearn_1540954231561/azureml-logs/60_control_log.txt?sv=2017-04-17&sr=b&sig=fZkIJpio9XIXQP%2FujusxT54xA45pdDOisv9kSIRRXzM%3D&st=2018-10-31T02%3A44%3A49Z&se=2018-10-31T10%3A54%3A49Z&sp=r',\n",
       "  'azureml-logs/azureml.log': 'https://jkamllab4248191217.blob.core.windows.net/azureml/ExperimentRun/aerial-train-sklearn_1540954231561/azureml-logs/azureml.log?sv=2017-04-17&sr=b&sig=6%2F0n9usBk1KV33lwbWFCYOLoRbG%2B%2B%2FQxJ0WY8jiJtPI%3D&st=2018-10-31T02%3A44%3A49Z&se=2018-10-31T10%3A54%3A49Z&sp=r',\n",
       "  'azureml-logs/80_driver_log.txt': 'https://jkamllab4248191217.blob.core.windows.net/azureml/ExperimentRun/aerial-train-sklearn_1540954231561/azureml-logs/80_driver_log.txt?sv=2017-04-17&sr=b&sig=N2D%2BLy25rgWJ4F8SiDvnfSmpzaNjXK%2BxJnS8q3nygiY%3D&st=2018-10-31T02%3A44%3A49Z&se=2018-10-31T10%3A54%3A49Z&sp=r'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ds.path('bottleneck').as_download(),\n",
    "    '--training-file-name': 'aerial_bottleneck_train_vgg16.h5',\n",
    "    '--validation-file-name': 'aerial_bottleneck_valid_vgg16.h5',\n",
    "    '--regularization': 0.8\n",
    "}\n",
    "\n",
    "pip_packages = ['h5py','pillow','scikit-learn']\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=dsvm_compute,\n",
    "                entry_script='train.py',\n",
    "                pip_packages=pip_packages\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the job\n",
    "\n",
    "Run the experiment by submitting the estimator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {\"RunName\": \"train-sklearn\"}\n",
    "\n",
    "run = exp.submit(config=est, tags=tags)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the call is asynchronous, it returns a **Preparing** or **Running** state as soon as the job is started.\n",
    "\n",
    "### Monitor a remote run\n",
    "\n",
    "In total, the first run takes **approximately 10 minutes**. But for subsequent runs, as long as the script dependencies don't change, the same image is reused and hence the container start up time is much faster.\n",
    "\n",
    "Here is what's happening while you wait:\n",
    "\n",
    "- **Image creation**: A Docker image is created matching the Python environment specified by the estimator. The image is uploaded to the workspace. This stage happens once for each Python environment since the container is cached for subsequent runs.  During image creation, logs are streamed to the run history. You can monitor the image creation progress using these logs.\n",
    "\n",
    "- **Scaling**: If the remote cluster requires more nodes to execute the run than currently available, additional nodes are added automatically. \n",
    "\n",
    "- **Running**: In this stage, the necessary scripts and files are sent to the compute target, then data stores are mounted/copied, then the entry_script is run. While the job is running, stdout and the ./logs directory are streamed to the run history. You can monitor the run's progress using these logs.\n",
    "\n",
    "- **Post-Processing**: The ./outputs directory of the run is copied over to the run history in your workspace so you can access these results.\n",
    "\n",
    "\n",
    "You can check the progress of a running job in multiple ways. This tutorial uses a Jupyter widget as well as a `wait_for_completion` method. \n",
    "\n",
    "### Jupyter widget\n",
    "\n",
    "Watch the progress of the run with a Jupyter widget.  Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes. \n",
    "\n",
    "Note: Currently, there is a problem with RunDetails widget in DSVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get log results upon completion\n",
    "\n",
    "Model training and monitoring happen in the background. Wait until the model has completed training before running more code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=False) # specify True for a verbose log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display run results\n",
    "\n",
    "The training has completed. You can see the logs generated during the run by executing `Run.get_file_names()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run.get_file_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step\n",
    "\n",
    "You can improve the performance of the network by fine tuning hyper-parameters. In the next part of the lab you will use AML technology called `hyperdrive` to try different combinations of hyper parameters by running concurrent training job on a GPU cluser.\n",
    "\n",
    " Continue to `03-hyperdrive`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up resources\n",
    "\n",
    "Before you move to the next step, you can delete the GPU VM. We will not need it anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsvm_compute.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
