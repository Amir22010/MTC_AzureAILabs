{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Experimenting in a local environment\n",
    "In this lab you will experiment with a couple of machine learning algorithms using a small development dataset and local storage and compute. In many cases, your local development environment will not have enough computational and storage resources to support training on full datasets. A common machine learning workflow pattern is to develop and debug your training scripts in a local environment and then run training jobs on full datasets using powerfull cloud compute resources.\n",
    "\n",
    "You will use Azure Machine Learning service to track your training runs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dowload the development dataset\n",
    "\n",
    "The datasets used in the labs have been uploaded to a public container in Azure Blob Storage.\n",
    "\n",
    "Download the small development dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12\n",
      "drwxrwxr-x 8 demouser demouser 4096 Oct  6 17:45 test\n",
      "drwxrwxr-x 8 demouser demouser 4096 Oct  6 17:45 train\n",
      "drwxrwxr-x 8 demouser demouser 4096 Oct  6 17:45 valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-02 15:29:54 URL:https://azureailabs.blob.core.windows.net/aerialtar/aerialtiny.tar.gz [103131426/103131426] -> \"/tmp/aerialtiny.tar.gz\" [1]\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "wget -nv https://azureailabs.blob.core.windows.net/aerialtar/aerialtiny.tar.gz -P /tmp\n",
    "tar -xf /tmp/aerialtiny.tar.gz -C /tmp\n",
    "ls -l /tmp/aerialtiny\n",
    "ls -l /tmp/aerialtiny/train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three datasets: training, validation, and testing. The datasets are organized into six folders, each folder containing images of a given land class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and label images\n",
    "\n",
    "Load the training and validation datasets to `numpy` arrays and assign numeric labels representing land classes. The images are in `PNG` format. The size is `(224, 224, 3)` and the color encoding is `RGB`\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1060, 224, 224, 3)\n",
      "(1060,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "\n",
    "# Define a utility function to load images from a folder\n",
    "def load_images(input_dir):\n",
    "    label_to_integer = {\n",
    "        \"Barren\": 0,\n",
    "        \"Cultivated\": 1,\n",
    "        \"Developed\": 2,\n",
    "        \"Forest\": 3,\n",
    "        \"Herbaceous\": 4,\n",
    "        \"Shrub\": 5}\n",
    "    \n",
    "    images = [(imread(os.path.join(input_dir, folder, filename)), label_to_integer[folder])\n",
    "             for folder in os.listdir(input_dir)\n",
    "             for filename in os.listdir(os.path.join(input_dir, folder))]\n",
    "    \n",
    "    images, labels = zip(*images)\n",
    "    \n",
    "    return np.asarray(images), np.asarray(labels)\n",
    "\n",
    "\n",
    "# Load training images\n",
    "training_images_dir = '/tmp/aerialtiny/train'\n",
    "training_images, training_labels = load_images(training_images_dir)\n",
    "\n",
    "# Load validation images\n",
    "validation_images_dir = '/tmp/aerialtiny/valid'\n",
    "validation_images, validation_labels = load_images(validation_images_dir)\n",
    "\n",
    "print(training_images.shape)\n",
    "print(training_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a local model\n",
    "In this step you will train a logistic regression model from `sckit-learn`, directly on image pixel data. This is a little bit of a naive approach as experience teaches us that simple machine learning models don't perform well on raw image data unless dealing with really simplistic scenarios like the MNIST dataset. Nevertheleess, we will use this approach to demostrate how to track the training progress using AML Experiment and Run entities. In the following labs you will utilize Transfer Learning to train much better classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to AML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /home/demouser/repos/MTC_AzureAILabs/DataScienceTrack/01-aml-walkthrough-sklearn/aml_config/config.json\n",
      "jkamllab\n",
      "jkamllab\n",
      "eastus2\n",
      "952a710c-8d9c-40c1-9fec-f752138cc0b3\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess images\n",
    "Since our images are in (224, 224,3 ) RGB format we need to flatten them to conform to the input shape required by logistic regression and other sckit-learn ml algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:\n",
      "  Training images:  (1060, 150528)\n",
      "  Training labels:  (1060,)\n"
     ]
    }
   ],
   "source": [
    "# Reshape training and validation datasets\n",
    "X_train = np.ndarray.reshape(training_images, (training_images.shape[0], -1))\n",
    "X_validate = np.ndarray.reshape(validation_images, (validation_images.shape[0], -1))\n",
    "y_train = training_labels\n",
    "y_valid = validation_labels\n",
    "\n",
    "# Print the shape of inputs\n",
    "print(\"Input data:\")\n",
    "print(\"  Training images: \", X_train.shape)\n",
    "print(\"  Training labels: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a model\n",
    "We will track the model's hyper-parameters, performance, and serialized model file in AML Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "# Create AML Experiment\n",
    "experiment_name = 'aerial-train-in-notebook'\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "\n",
    "# Initialize logging\n",
    "run = exp.start_logging()\n",
    "\n",
    "# Log run description and hyper-parameter values\n",
    "run.tag(\"Description\", \"Naive attempt to fit logistic regression to aerial image data\")\n",
    "run.log(\"Solver\", \"lbfgs\")\n",
    "run.log(\"C\", 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training. After training completes calculate performance on the validation data set and log them in Azure experiment. Also, push the serialized model to the AML experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/demouser/anaconda3/envs/aml/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:718: UserWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed.\n",
      "Starting evaluation\n",
      "Validation accuracy: 0.3978494623655914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Train logistic regression\n",
    "print(\"Starting training ...\")\n",
    "lr = LogisticRegression(\n",
    "    multi_class='multinomial',\n",
    "    solver='lbfgs',\n",
    "    C = 1.0,\n",
    "    verbose=1)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"Training completed.\")\n",
    "\n",
    "# Evaluate the model on validation images\n",
    "print(\"Starting evaluation\")\n",
    "y_hat = lr.predict(X_validate)\n",
    "val_accuracy = np.average(y_hat == y_valid)\n",
    "print(\"Validation accuracy:\", val_accuracy)\n",
    "run.log('Validation accuracy', val_accuracy)\n",
    "\n",
    "# Save and upload the model\n",
    "joblib.dump(value=lr, filename='model.pkl')\n",
    "run.upload_file(name='outputs/model.pkl', path_or_stream='./model.pkl')\n",
    "\n",
    "# Finalize the run\n",
    "run.complete()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can browse the recorded run in Azure portal.\n",
    "\n",
    "As shown by the validation accuracy, our model's performance is rather absymal. Logistic regression can only learn linear decision boundries and cannot handle a complex dataset like our land images. Let's try an ML algorithm with more capacity - Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   11.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed.\n",
      "Starting evaluation\n",
      "Validation accuracy: 0.6881720430107527\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize logging\n",
    "run = exp.start_logging()\n",
    "\n",
    "# Log run description and hyper-parameter values\n",
    "run.tag(\"Description\", \"Another naive attempt to train on aerial image data - random forests\")\n",
    "run.log(\"No of trees\", 100)\n",
    "run.log(\"Max Depth\", 7)\n",
    "\n",
    "# Train logistic regression\n",
    "print(\"Starting training ...\")\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=7,\n",
    "    verbose=1)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"Training completed.\")\n",
    "\n",
    "# Evaluate the model on validation images\n",
    "print(\"Starting evaluation\")\n",
    "y_hat = rf.predict(X_validate)\n",
    "val_accuracy = np.average(y_hat == y_valid)\n",
    "print(\"Validation accuracy:\", val_accuracy)\n",
    "run.log('Validation accuracy', val_accuracy)\n",
    "\n",
    "# Save and upload the model\n",
    "joblib.dump(value=lr, filename='model.pkl')\n",
    "run.upload_file(name='outputs/model.pkl', path_or_stream='./model.pkl')\n",
    "\n",
    "# Finalize the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much better than logistic regression but still pretty bad. We could attempt to fine-tune hyper-parameters or try other machine learning algorithms but rather thank pursuing these approaches we will apply a proven technique that has emerged in the recent years - Transfer Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step\n",
    "\n",
    "In the next lab you will utilize a pre-trained deep neural network to extract powerful features from images and use them to train a better performing classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
