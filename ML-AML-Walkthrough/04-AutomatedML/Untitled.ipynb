{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /data/home/demouser/notebooks/MTC_AzureAILabs/ML-AML-Walkthrough/aml_config/config.json\n",
      "jkamlworkshop\n",
      "jkamlworkshop\n",
      "southcentralus\n",
      "952a710c-8d9c-40c1-9fec-f752138cc0b3\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "# Read the workspace config from file\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target, using this compute target instead of creating:  cpu-cluster\n"
     ]
    }
   ],
   "source": [
    "# Create an Azure ML Compute cluster\n",
    "\n",
    "# Create Azure ML cluster\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"cpu-cluster\"\n",
    "cluster_min_nodes = 1\n",
    "cluster_max_nodes = 3\n",
    "vm_size = \"STANDARD_DS11_V2\"\n",
    "\n",
    "# Check if the cluster exists. If yes connect to it\n",
    "if cluster_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[cluster_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('Found existing compute target, using this compute target instead of creating:  ' + cluster_name)\n",
    "    else:\n",
    "        print(\"Error: A compute target with name \",cluster_name,\" was found, but it is not of type AmlCompute.\")\n",
    "else:\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size, \n",
    "                                                                min_nodes = cluster_min_nodes, \n",
    "                                                                max_nodes = cluster_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "     # For a more detailed view of current BatchAI cluster status, use the 'status' property    \n",
    "    print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core import Run\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "# create a new RunConfig object\n",
    "run_config = RunConfiguration(framework=\"python\")\n",
    "\n",
    "# Azure ML Compute cluster for Automated ML jobs require docker.\n",
    "run_config.environment.docker.enabled = True\n",
    "\n",
    "# Set compute target to Azure ML Compute cluster\n",
    "run_config.target = compute_target\n",
    "\n",
    "# Set data references\n",
    "#run_config.data_references = {ds.name: dr}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "project_folder = './project'\n",
    "script_name = 'get_data.py'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./project/get_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $project_folder/get_data.py\n",
    "\n",
    "from sklearn import datasets\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "def get_data():\n",
    "    \n",
    "    digits = datasets.load_digits()\n",
    "    X_train = digits.data\n",
    "    y_train = digits.target\n",
    "\n",
    "    return { \"X\" : X_train, \"y\" : y_train }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "import logging\n",
    "\n",
    "\n",
    "automl_settings = {\n",
    "    \"iteration_timeout_minutes\": 2,\n",
    "    \"iterations\": 20,\n",
    "    \"n_cross_validations\": 5,\n",
    "    \"primary_metric\": 'AUC_weighted',\n",
    "    \"preprocess\": False,\n",
    "    \"max_concurrent_iterations\": 5,\n",
    "    \"verbosity\": logging.INFO\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             debug_log = 'automl_errors.log',\n",
    "                             path = project_folder,\n",
    "                             run_configuration=run_config,\n",
    "                             data_script = project_folder + \"/get_data.py\",\n",
    "                             **automl_settings\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "experiment_name = 'automl-remote-batchai'\n",
    "experiment = Experiment(ws, experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on remote compute: cpu-cluster\n",
      "Parent Run ID: AutoML_9f65abc9-1cbc-43a3-a965-752d3f32b900\n",
      "*******************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "*******************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   StandardScalerWrapper KNN                      0:01:01       0.9982    0.9982\n",
      "         1   StandardScalerWrapper KNN                      0:01:30       0.9989    0.9989\n",
      "         2   MaxAbsScaler LightGBM                          0:02:18       0.9968    0.9989\n",
      "         3   RobustScaler LinearSVM                         0:02:49       0.9846    0.9989\n",
      "         4   MaxAbsScaler ExtremeRandomTrees                0:03:18       0.9890    0.9989\n",
      "         5   StandardScalerWrapper LightGBM                 0:03:18       0.9931    0.9989\n",
      "         6   StandardScalerWrapper LogisticRegression       0:03:20       0.9950    0.9989\n",
      "         7   StandardScalerWrapper SGD                      0:03:05       0.9923    0.9989\n",
      "        10   StandardScalerWrapper LightGBM                 0:02:19       0.9992    0.9992\n",
      "        11   StandardScalerWrapper LightGBM                 0:02:19       0.9981    0.9992\n",
      "         8   TruncatedSVDWrapper KNN                        0:04:37       0.9990    0.9992\n",
      "         9   StandardScalerWrapper LightGBM                 0:04:20       0.9989    0.9992\n",
      "        12   StandardScalerWrapper LightGBM                 0:02:19       0.9991    0.9992\n",
      "        13   StandardScalerWrapper GradientBoosting         0:03:41          nan    0.9992\n",
      "ERROR:                                                 \n",
      "        14   StandardScalerWrapper LightGBM                 0:01:20       0.9951    0.9992\n",
      "        15   StandardScalerWrapper LogisticRegression       0:00:55       0.9969    0.9992\n",
      "        16   StandardScalerWrapper LightGBM                 0:01:19       0.9981    0.9992\n",
      "        17   MinMaxScaler LightGBM                          0:01:07       0.9993    0.9993\n",
      "        18   TruncatedSVDWrapper LightGBM                   0:01:19       0.9881    0.9993\n",
      "        19    Ensemble                                      0:01:19       0.9998    0.9998\n"
     ]
    }
   ],
   "source": [
    "\n",
    "remote_run = experiment.submit(automl_config, show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
