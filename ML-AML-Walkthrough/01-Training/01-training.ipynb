{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Training a Machine Learning Model\n",
    "\n",
    "The goal of this lab is to demonstarte how to use Azure Machine Learning service to orchestrate machine learning **training** workflows. \n",
    "\n",
    "To keep the focus of the lab on **workflow orchestration** rather then on idiosyncrasies of a domain problem, we have chosen a relatively simple machine learning scenario.\n",
    "\n",
    "During the lab you will learn how to:\n",
    "- Track training iterations a.k.a *Runs* in *Azure ML Experiment*\n",
    "- Execute training scripts on remote, cloud compute resources - *Azure ML Compute*.\n",
    "- Register the best performing model with *Azure ML Model Registry*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "You will train a binary classification model to predict propensity to purchase. The dataset comes from the UCI Machine Learning repository, and it is related to direct marketing campaigns (phone calls) of a Portuguese banking institution. The goal of the model is to help with campaign planning by predicting which clients will respond positively to marketing phone calls. \n",
    "\n",
    "\n",
    "## Connect AML workspace\n",
    "\n",
    "Check the version of AML SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK Version: 1.0.6\n"
     ]
    }
   ],
   "source": [
    "# Verify AML SDK Installed\n",
    "\n",
    "import azureml.core\n",
    "print(\"SDK Version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /data/home/demouser/notebooks/aml_config/config.json\n",
      "jkamlworkshop\n",
      "jkamlworkshop\n",
      "southcentralus\n",
      "952a710c-8d9c-40c1-9fec-f752138cc0b3\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "# Connect to workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "### Download the dataset\n",
    "The dataset used in the lab can be downloaded from a public Azure Blob Storage container.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wget -O ../datasets/banking_train.csv https://azureailabs.blob.core.windows.net/banking/banking_train.csv\n",
      "wget -O ../datasets/banking_test.csv https://azureailabs.blob.core.windows.net/banking/banking_test.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['banking_test.csv', 'banking_train.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder = '../datasets'\n",
    "filenames = ['banking_train.csv','banking_test.csv']\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "for filename in filenames:\n",
    "    downloadCommand = 'wget -O ''{0}/{1}'' ''https://azureailabs.blob.core.windows.net/banking/{1}'''.format(folder, filename)\n",
    "    print(downloadCommand)\n",
    "    os.system(downloadCommand)\n",
    "os.listdir(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32950 entries, 0 to 32949\n",
      "Data columns (total 21 columns):\n",
      "age               32950 non-null int64\n",
      "job               32950 non-null object\n",
      "marital           32950 non-null object\n",
      "education         32950 non-null object\n",
      "default           32950 non-null object\n",
      "housing           32950 non-null object\n",
      "loan              32950 non-null object\n",
      "contact           32950 non-null object\n",
      "month             32950 non-null object\n",
      "day_of_week       32950 non-null object\n",
      "duration          32950 non-null int64\n",
      "campaign          32950 non-null int64\n",
      "pdays             32950 non-null int64\n",
      "previous          32950 non-null int64\n",
      "poutcome          32950 non-null object\n",
      "emp_var_rate      32950 non-null float64\n",
      "cons_price_idx    32950 non-null float64\n",
      "cons_conf_idx     32950 non-null float64\n",
      "euribor3m         32950 non-null float64\n",
      "nr_employed       32950 non-null float64\n",
      "y                 32950 non-null int64\n",
      "dtypes: float64(5), int64(6), object(10)\n",
      "memory usage: 5.3+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jul</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.960</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>wed</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.964</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>self-employed</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.962</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>admin.</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.958</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>admin.</td>\n",
       "      <td>divorced</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.962</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age            job   marital            education default housing loan  \\\n",
       "0   33     technician   married  professional.course      no     yes   no   \n",
       "1   31     unemployed   married    university.degree      no     yes   no   \n",
       "2   41  self-employed   married             basic.9y      no     yes   no   \n",
       "3   29         admin.    single    university.degree      no      no  yes   \n",
       "4   39         admin.  divorced          high.school      no     yes   no   \n",
       "\n",
       "     contact month day_of_week ...  campaign  pdays  previous     poutcome  \\\n",
       "0  telephone   jul         mon ...        17    999         0  nonexistent   \n",
       "1   cellular   aug         wed ...        11    999         0  nonexistent   \n",
       "2   cellular   jul         fri ...         2    999         0  nonexistent   \n",
       "3   cellular   jul         thu ...         2    999         0  nonexistent   \n",
       "4   cellular   jul         mon ...         5    999         0  nonexistent   \n",
       "\n",
       "  emp_var_rate  cons_price_idx  cons_conf_idx  euribor3m  nr_employed  y  \n",
       "0          1.4          93.918          -42.7      4.960       5228.1  0  \n",
       "1          1.4          93.444          -36.1      4.964       5228.1  0  \n",
       "2          1.4          93.918          -42.7      4.962       5228.1  0  \n",
       "3          1.4          93.918          -42.7      4.958       5228.1  1  \n",
       "4          1.4          93.918          -42.7      4.962       5228.1  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "folder = '../datasets'\n",
    "filename = 'banking_train.csv'\n",
    "pathname = os.path.join(folder, filename)\n",
    "df = pd.read_csv(pathname, delimiter=',')\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset combines the information about the bank's customers with the results of previous campaigns and key economic indicators. It includes 41,188 records and 21 fields. The columns are a mix of numeric and categorical data types.\n",
    "\n",
    "The `y` column indicates whether the customer subscribed to a term deposit. This is our `target` variable or `label`. The goal of the model is to predict this column on new examples.\n",
    "\n",
    "Some information that exists in the historical dataset will not be available when planning a new campaign. \n",
    "\n",
    "Please refer to [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/bank+marketing) for more information. \n",
    "\n",
    "We will use the following features for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>education</th>\n",
       "      <th>marital</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>month</th>\n",
       "      <th>campaign</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>technician</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>married</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>jul</td>\n",
       "      <td>17</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.960</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>married</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>aug</td>\n",
       "      <td>11</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.964</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>self-employed</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>married</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>jul</td>\n",
       "      <td>2</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.962</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>admin.</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>single</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>jul</td>\n",
       "      <td>2</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.958</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>admin.</td>\n",
       "      <td>high.school</td>\n",
       "      <td>divorced</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>jul</td>\n",
       "      <td>5</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.962</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age            job            education   marital housing loan month  \\\n",
       "0   33     technician  professional.course   married     yes   no   jul   \n",
       "1   31     unemployed    university.degree   married     yes   no   aug   \n",
       "2   41  self-employed             basic.9y   married     yes   no   jul   \n",
       "3   29         admin.    university.degree    single      no  yes   jul   \n",
       "4   39         admin.          high.school  divorced     yes   no   jul   \n",
       "\n",
       "   campaign     poutcome  emp_var_rate  cons_price_idx  cons_conf_idx  \\\n",
       "0        17  nonexistent           1.4          93.918          -42.7   \n",
       "1        11  nonexistent           1.4          93.444          -36.1   \n",
       "2         2  nonexistent           1.4          93.918          -42.7   \n",
       "3         2  nonexistent           1.4          93.918          -42.7   \n",
       "4         5  nonexistent           1.4          93.918          -42.7   \n",
       "\n",
       "   euribor3m  nr_employed  y  \n",
       "0      4.960       5228.1  0  \n",
       "1      4.964       5228.1  0  \n",
       "2      4.962       5228.1  0  \n",
       "3      4.958       5228.1  1  \n",
       "4      4.962       5228.1  0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = [\n",
    "                   # Demographic\n",
    "                   'age', \n",
    "                   'job', \n",
    "                   'education', \n",
    "                   'marital',  \n",
    "                   'housing', \n",
    "                   'loan', \n",
    "                   # Previous campaigns\n",
    "                   'month',\n",
    "                   'campaign',\n",
    "                   'poutcome',\n",
    "                   # Economic indicators\n",
    "                   'emp_var_rate',\n",
    "                   'cons_price_idx',\n",
    "                   'cons_conf_idx',\n",
    "                   'euribor3m',\n",
    "                   'nr_employed']\n",
    "\n",
    "df_train = df[feature_columns + ['y']]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Scikit-learn` estimators expect continuous input. Some of the features in the dataset are categorical and encoded as strings. We will use *dummy* encoding to convert categorical features to numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, drop_first=True).astype(dtype='float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the class distribution in training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x7ff9efea8710>,\n",
       "  <matplotlib.axis.XTick at 0x7ff9efe91fd0>],\n",
       " <a list of 2 Text xticklabel objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar([0, 1], df_train.y.value_counts())\n",
    "plt.xticks([0, 1], [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataset is very imbalanced. We will need to address this when configuring training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "In this section of the lab you will train a binary classification model.\n",
    "\n",
    "You will first run training on a local workstation and use Azure Machine Learning Experiment to track training progress. In the following step, you will use Azure Machine Learning Compute to run  training on more powerful cloud compute resources.\n",
    "\n",
    "In the Azure Machine Learning service, you can track training artifacts (algorithm settings, performance metrics, logs, serialized models, etc.)  created during training iterations a.k.a *Runs* using Azure ML *Experiment*. To do that you must instrument your code with logging statements and trigger logging when you submit the *Run*. The following are two ways to trigger the run submission:\n",
    "\n",
    "- Start an interactive logging session in the specified *Experiment*. As you execute logging statements, any artifacts that are logged during the session are added to the run record in the experiment. We will use this approach when training the model on a local compute.\n",
    "\n",
    "- Add logging functions to your training script and trigger logging when submitting the script to run on a compute target. With this option, you can add monitoring code to be notified of completion or to get a visual widget to monitor. We will demonstrate this approach when training on a remote Azure Machine Learning Compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a local workstation\n",
    "#### Prepare training pipeline\n",
    "\n",
    "We are going to train a binomial *LogisticRegression* regression model. *LogisticRegression* exposes a number of tuneable hyperparameters. Argueable, the most important setting is the inverse of regularization strength **C** . For the sake of simplicity, we will focus on tuning this hyperparameter when training our model. We will use *GridSearchCV* to automate the hyperparameter tuning process. \n",
    "\n",
    "The business goal of our model is to identify customers with high propencity to buy. As such, we want to minimize the number of false negatives - customers who were wrongly identified as ones with low propencity to buy. We want the model with a high *recall*.\n",
    "\n",
    "Since the dataset is imbalanced we will set *class_weight* parameter to `balanced` to automatically adjust weights inversely proportional to class frequencies in in the input data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Create logistic regression estimater\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=300, class_weight='balanced')\n",
    "\n",
    "# Logistic regression requires feature scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create a training pipeline\n",
    "pipeline = Pipeline(steps=[('scaler', scaler),\n",
    "                           ('lr', lr)])\n",
    "\n",
    "# Configure grid search\n",
    "param_grid = {'lr__C': [0.1, 0.5, 1, 2, 5]}\n",
    "clf = GridSearchCV(pipeline,\n",
    "                   param_grid, \n",
    "                   cv=5, \n",
    "                   scoring=['recall', 'accuracy'],\n",
    "                   refit = 'recall',\n",
    "                   return_train_score = False\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Execute training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=300,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'lr__C': [0.1, 0.5, 1, 2, 5]}, pre_dispatch='2*n_jobs',\n",
       "       refit='recall', return_train_score=False,\n",
       "       scoring=['recall', 'accuracy'], verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_train.drop('y', axis=1)\n",
    "y = df_train.y\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Track the run in Azure Machine Learning Experiment\n",
    "\n",
    "The training run has completed and the *GridSearchCV* object contains the results for each value of **C**.\n",
    "\n",
    "We will now persists the results in *Azure ML Experiment*.\n",
    "\n",
    "An experiment is a grouping of many runs from a specified script. It always belongs to a workspace. \n",
    "\n",
    "Create an *Experiment* to track run records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "exp = Experiment(ws, \"propensity_to_buy_classifier_local_training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we used *GridSearchCV* to train multiple models with different setting for **C** we want to reflect this approach in a run record. One way to do that is to create a hierarcical run record structure mapping directly to our grid search training regime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing C: 0.1 and accuracy: 0.8260698027314113 and recall: 0.6298524017960675 in Run object\n",
      "Storing C: 0.5 and accuracy: 0.8271623672230652 and recall: 0.6287739945550839 in Run object\n",
      "Storing C: 1 and accuracy: 0.8274051593323217 and recall: 0.6287739945550839 in Run object\n",
      "Storing C: 2 and accuracy: 0.8274051593323217 and recall: 0.6282355548538359 in Run object\n",
      "Storing C: 5 and accuracy: 0.8274962063732929 and recall: 0.6282355548538359 in Run object\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.run import Run\n",
    "\n",
    "# Create a root run\n",
    "root_run = exp.start_logging()\n",
    "\n",
    "# Retrieve training results from GridSearchCV object and store them in child runs of the root run\n",
    "for C, accuracy, recall in zip(clf.cv_results_['params'], clf.cv_results_['mean_test_accuracy'], clf.cv_results_['mean_test_recall']):\n",
    "    run = root_run.child_run(\"Run with C set to {}\".format(C))\n",
    "    run.log(\"C\", C['lr__C'])\n",
    "    run.log(\"Accuracy\", accuracy)\n",
    "    run.log(\"Recall\", recall)\n",
    "    run.complete()\n",
    "    print(\"Storing C: {} and accuracy: {} and recall: {} in Run object\".format(C['lr__C'], accuracy, recall))\n",
    "    \n",
    "# Close the parent run in the experiment\n",
    "root_run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have captured history for various runs, you can review the runs. \n",
    "\n",
    "There are three ways to access information captured in *Azure ML Experiment*:\n",
    "\n",
    "- Using Azure ML Workspace web GUI in Azure Portal\n",
    "- Using Azure ML CLI\n",
    "- Programatically, using Azure ML SDK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'runId': '4d9d9c99-c3b7-42c7-8b96-2a64ecc431a8', 'target': 'sdk', 'status': 'Completed', 'startTimeUtc': '2019-01-15T17:05:46.124863Z', 'endTimeUtc': '2019-01-15T17:05:46.558285Z', 'properties': {}, 'logFiles': {}}\n",
      "{'C': 5, 'Accuracy': 0.8274962063732929, 'Recall': 0.6282355548538359}\n",
      "------------------------------------------------------------\n",
      "{'runId': 'f62b6fd8-9a54-468f-8e8b-2017d6a7f4a0', 'target': 'sdk', 'status': 'Completed', 'startTimeUtc': '2019-01-15T17:05:45.315471Z', 'endTimeUtc': '2019-01-15T17:05:45.67973Z', 'properties': {}, 'logFiles': {}}\n",
      "{'C': 2, 'Accuracy': 0.8274051593323217, 'Recall': 0.6282355548538359}\n",
      "------------------------------------------------------------\n",
      "{'runId': '175bcd35-1797-41db-9f5f-f152f6df6df7', 'target': 'sdk', 'status': 'Completed', 'startTimeUtc': '2019-01-15T17:05:44.580425Z', 'endTimeUtc': '2019-01-15T17:05:44.95823Z', 'properties': {}, 'logFiles': {}}\n",
      "{'C': 1, 'Accuracy': 0.8274051593323217, 'Recall': 0.6287739945550839}\n",
      "------------------------------------------------------------\n",
      "{'runId': '1009dd51-4191-4fd0-9b00-c7bd7289ce62', 'target': 'sdk', 'status': 'Completed', 'startTimeUtc': '2019-01-15T17:05:43.426523Z', 'endTimeUtc': '2019-01-15T17:05:43.80785Z', 'properties': {}, 'logFiles': {}}\n",
      "{'C': 0.5, 'Accuracy': 0.8271623672230652, 'Recall': 0.6287739945550839}\n",
      "------------------------------------------------------------\n",
      "{'runId': 'ca9dcb21-5a24-4026-a201-18afd76b271d', 'target': 'sdk', 'status': 'Completed', 'startTimeUtc': '2019-01-15T17:05:42.751143Z', 'endTimeUtc': '2019-01-15T17:05:43.123957Z', 'properties': {}, 'logFiles': {}}\n",
      "{'C': 0.1, 'Accuracy': 0.8260698027314113, 'Recall': 0.6298524017960675}\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# List all child runs\n",
    "runs = [r for r in root_run.get_children()]\n",
    "\n",
    "for run in runs:\n",
    "    print(run.get_details())\n",
    "    print(run.get_metrics())\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train remotely using Azure ML Compute\n",
    "\n",
    "Up until now, all of your training was executed locally on the same machine running Jupyter. Now you will execute the same logic targeting a remote Azure ML Compute.\n",
    "\n",
    "A compute target is the compute resource that you use to run your training script or host your service deployment. Compute targets are attached to a workspace. Compute targets other than the local machine are shared by users of the workspace.\n",
    "\n",
    "There are two types of compute targets: managed and unmanaged:\n",
    "\n",
    "- **Managed**: Compute targets that are created and managed by Azure Machine Learning service. These compute targets are optimized for machine learning workloads. Currently, Azure Machine Learning Compute is the only managed compute target. Additional managed compute targets may be added in the future. You can create machine learning compute instances directly through the workspace by using the Azure portal, the Azure Machine Learning SDK, or the Azure CLI. All other compute targets must be created outside the workspace and then attached to it.\n",
    "\n",
    "- **Unmanaged**: Compute targets that are not managed by Azure Machine Learning service. You might need to create them outside Azure Machine Learning and then attach them to your workspace before use. Unmanaged compute targets can require additional steps for you to maintain or to improve performance for machine learning workloads.\n",
    "\n",
    "In this lab we are going to utilize Azure Machine Learning Compute.\n",
    "\n",
    "\n",
    "#### Provision Azure ML Compute Cluster\n",
    "\n",
    "We will provision an autoscale Azure ML Computer Cluster. In this lab we will only use a single node on the cluster. In the following labs we will utilize multiple nodes on the cluster to run parallel model selection and hyper parameter tuning jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new compute target...\n",
      "Creating\n",
      "Succeeded............\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-01-15T17:08:24.739000+00:00', 'creationTime': '2019-01-15T17:06:45.452061+00:00', 'currentNodeCount': 1, 'errors': None, 'modifiedTime': '2019-01-15T17:07:24.129871+00:00', 'nodeStateCounts': {'idleNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0, 'preparingNodeCount': 1, 'runningNodeCount': 0, 'unusableNodeCount': 0}, 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 1, 'maxNodeCount': 3, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'targetNodeCount': 1, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_DS11_V2'}\n"
     ]
    }
   ],
   "source": [
    "# Create an Azure ML Compute cluster\n",
    "\n",
    "# Create Azure ML cluster\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"cpu-cluster\"\n",
    "cluster_min_nodes = 1\n",
    "cluster_max_nodes = 3\n",
    "vm_size = \"STANDARD_DS11_V2\"\n",
    "\n",
    "# Check if the cluster exists. If yes connect to it\n",
    "if cluster_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[cluster_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('Found existing compute target, using this compute target instead of creating:  ' + cluster_name)\n",
    "    else:\n",
    "        print(\"Error: A compute target with name \",cluster_name,\" was found, but it is not of type AmlCompute.\")\n",
    "else:\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size, \n",
    "                                                                min_nodes = cluster_min_nodes, \n",
    "                                                                max_nodes = cluster_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "     # For a more detailed view of current BatchAI cluster status, use the 'status' property    \n",
    "    print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload data to AML DataStore\n",
    "With your cluster ready, you need to upload the training data to a location accessible by the cluster's nodes. \n",
    "\n",
    "*Datastore* is a storage abstraction over an Azure storage account. The datastore can use either an Azure blob container or an Azure file share as the back-end storage. Each workspace has a default datastore, and you can register additional datastores.\n",
    "\n",
    "We will upload the training data to the default Datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureBlob jkamlworstoragedirzndtd azureml-blobstore-5635fa3a-71d5-4d1b-bc80-b0847d6f842b\n",
      "Uploading ../datasets/banking_test.csv\n",
      "Uploading ../datasets/banking_train.csv\n",
      "Uploaded ../datasets/banking_test.csv, 1 files out of an estimated total of 2\n",
      "Uploaded ../datasets/banking_train.csv, 2 files out of an estimated total of 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_e919859c06c24a15b4120214ddc4cd64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the dataset to the DataStore\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "ds.upload(src_dir='../datasets', target_path='datasets', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a training script\n",
    "\n",
    "Next, you will need to create a training script that is similar to the code you have executed to train the model locally. The script will be executed remotely on Azure ML Compute.\n",
    "\n",
    "In the script we chose not to utilize *GridSearchCV* for hyperparameter tuning. The value of **C** to use in *LogisticRegression* model is passed as a command line parameter. In the next lab, we will demonstrate how to use *Azure ML Hyperdrive* to conduct hyperparameter tuning in parallel on a scale out cluster.\n",
    "\n",
    "Note that we are passing the location of the training file as a parameter of the script. \n",
    "\n",
    "The last few statements in the script copy the serialized model to the `./outputs` directory. The `./outputs` directory is one of the special directories in Azure ML. At the end of each run the contents of the directory is copied to to Azure Machine Learning Experiment associated with the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./script/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from azureml.core.run import Run\n",
    "\n",
    "# Retrieve command line arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-folder', type=str,  help='data folder mounting point')\n",
    "parser.add_argument('--filename', type=str,  help='training file name')\n",
    "parser.add_argument('--C', type=float , help='regularization')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Configure a path to training data\n",
    "data_folder = os.path.join(args.data_folder, 'datasets')\n",
    "print('Loading data from: ', data_folder)\n",
    "data_csv_path = os.path.join(data_folder, args.filename)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(data_csv_path)\n",
    "\n",
    "# Preprocess the data\n",
    "feature_columns = [\n",
    "                   # Demographic\n",
    "                   'age', \n",
    "                   'job', \n",
    "                   'education', \n",
    "                   'marital',  \n",
    "                   'housing', \n",
    "                   'loan', \n",
    "                   # Previous campaigns\n",
    "                   'month',\n",
    "                   'campaign',\n",
    "                   'poutcome',\n",
    "                   # Economic indicators\n",
    "                   'emp_var_rate',\n",
    "                   'cons_price_idx',\n",
    "                   'cons_conf_idx',\n",
    "                   'euribor3m',\n",
    "                   'nr_employed']\n",
    "\n",
    "df = df[feature_columns + ['y']]\n",
    "df_train = pd.get_dummies(df, drop_first=True).astype(dtype='float')\n",
    "\n",
    "# Create logistic regression estimater\n",
    "lr = LogisticRegression(solver='lbfgs', C=args.C, max_iter=300, class_weight='balanced')\n",
    "\n",
    "# Logistic regression requires feature scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create a training pipeline\n",
    "pipeline = Pipeline(steps=[('scaler', scaler),\n",
    "                           ('lr', lr)])\n",
    "\n",
    "\n",
    "# Train and evaluate the model using cross validation\n",
    "X = df_train.drop('y', axis=1)\n",
    "y = df_train.y\n",
    "\n",
    "# Evaluate mterics(s) by cross-validation\n",
    "print(\"Starting training ...\")\n",
    "scoring = ['accuracy', 'recall']\n",
    "scores = cross_validate(pipeline, X, y, \n",
    "                        cv=10, \n",
    "                        return_train_score=False,\n",
    "                        scoring=scoring)\n",
    "\n",
    "cv_accuracy = np.mean(scores['test_accuracy'])\n",
    "cv_recall = np.mean(scores['test_recall'])\n",
    "\n",
    "print(\"CV accuracy: \", cv_accuracy)\n",
    "print(\"CV recall: \", cv_recall)\n",
    "\n",
    "# Persist the metrics in Azure ML Experiment\n",
    "# Acquire the current run and log run parameters and performance measures\n",
    "run = Run.get_context()\n",
    "run.log(\"C\", args.C)\n",
    "run.log(\"CV Accuracy\", cv_accuracy)\n",
    "run.log(\"CV Recall\", cv_recall)\n",
    "\n",
    "\n",
    "# Train the model on a full dataset\n",
    "trained_pipeline = pipeline.fit(X, y)\n",
    "\n",
    "# Serialize the model to ./outputs directory so that it can be automatically copied to Azure ML Experiment\n",
    "print(\"Saving the model to outputs ...\")\n",
    "joblib.dump(value=trained_pipeline, filename='outputs/model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure a remote job\n",
    "\n",
    "A run configuration is a set of instructions that defines how a script should be run in a specified compute target. The configuration includes a wide set of behavior definitions, such as whether to use an existing Python environment or to use a Conda environment that's built from a specification.\n",
    "\n",
    "There are different ways of specifing a run configuration. We will use a higher level abstraction - the *Estimator*.\n",
    "\n",
    "The *Estimator* class allows to easily train models in the Azure ecosystem. You can create and use an Estimator object to submit any training code you want to run on remote compute, whether it's a single-node run or distributed training across a GPU cluster. For PyTorch and TensorFlow jobs, Azure Machine Learning also provides respective custom PyTorch and TensorFlow estimators to simplify using these frameworks.\n",
    "\n",
    "Notice that we are using `ds.as_mount()` method to pass a location of the training dataset on the default *Datastore* to the *Estimator* object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator\n",
    "#############################\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ds.as_mount(),\n",
    "    '--filename': 'banking_train.csv',\n",
    "    '--C': 2\n",
    "}\n",
    "\n",
    "est_config = Estimator(source_directory=script_folder,\n",
    "                       script_params=script_params,\n",
    "                       compute_target=compute_target,\n",
    "                       entry_script='train.py',\n",
    "                       conda_packages=['scikit-learn', 'pandas'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit the job\n",
    "\n",
    "Submit the job using the submit() method of the Experiment object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>propensity_to_buy_classifier_remote_training</td><td>propensity_to_buy_classifier_remote_training_1547572151850</td><td>azureml.scriptrun</td><td>Queued</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/952a710c-8d9c-40c1-9fec-f752138cc0b3/resourceGroups/jkamlworkshop/providers/Microsoft.MachineLearningServices/workspaces/jkamlworkshop/experiments/propensity_to_buy_classifier_remote_training/runs/propensity_to_buy_classifier_remote_training_1547572151850\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: propensity_to_buy_classifier_remote_training,\n",
       "Id: propensity_to_buy_classifier_remote_training_1547572151850,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Queued)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Execute the estimator job\n",
    "#####################################\n",
    "\n",
    "# Create a new experiment\n",
    "from azureml.core import Experiment\n",
    "experiment_name = \"propensity_to_buy_classifier_remote_training\"\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "\n",
    "# Submit the run\n",
    "tags = {\"Compute target\": \"Azure ML Compute\"}\n",
    "run = exp.submit(config=est_config, tags=tags)\n",
    "run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitor a remote run\n",
    "\n",
    "The call to start the run is asynchronous, it returns a **Starting** state as soon as the job is started.\n",
    "\n",
    "The first run takes longer. The subsequent runs, as long as the script dependencies don't change, are much faster.\n",
    "\n",
    "Here is what's happening while you wait:\n",
    "\n",
    "- **Image creation**: A Docker image is created matching the Python environment specified by the estimator. In our case, this will be a base CPU image with the  `scikit-learn`, and `pandas` libraries. The image is uploaded to the workspace. This stage happens once for each Python environment since the container is cached for subsequent runs.  During image creation, logs are streamed to the run history. You can monitor the image creation progress using these logs.\n",
    "\n",
    "- **Running**: In this stage, the training script is sent to the remote Azure ML Compute, then the data in the default datastore is copied to the local storage on the cluster node , then the script is run. While the job is running, stdout and the ./logs directory are streamed to the run history. You can monitor the run's progress using these logs. \n",
    "\n",
    "- **Post-Processing**:  The ./outputs directory on the cluster node  is copied over to the run history in the workspace.\n",
    "\n",
    "You can check the progress of a running job in multiple ways. Below cells demonstrate how to use a Jupyter widget as well as a `wait_for_completion` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73efe4ed854d42548e1a148cb5b46bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 's…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Create a monitoring widget\n",
    "RunDetails(run).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poll for job status\n",
    "run.wait_for_completion(show_output=True)  # value of True will display a verbose, streaming log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display files stored with the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run.get_file_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "\n",
    "In the next lab you will used *Azure ML Hyperdrive* to fine tune hyperparameters on a scale out cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "name": "01 model training",
  "notebookId": 863281121960369
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
