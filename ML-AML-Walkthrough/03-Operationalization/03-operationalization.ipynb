{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lab 4 - Model Deplyoment \n",
    "\n",
    "In this lab, you will learn how to use Azure Machine Learning Service to deploy, manage, and monitor the trained models.\n",
    "\n",
    "\n",
    "The following diagram illustrates the complete deployment workflow.\n",
    "\n",
    "![AML Arch](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/model-ci-cd.png)\n",
    "\n",
    "\n",
    "\n",
    "The deployment workflow includes the following steps:\n",
    "\n",
    "- Create/Retrain the model\n",
    "- Register the model in a registry hosted in your Azure Machine Learning Service workspace\n",
    "- Register an image that pairs a model with a scoring script and dependencies in a portable container\n",
    "- Deploy the image as a web service in the cloud or to edge devices\n",
    "- Monitor and collect data\n",
    "\n",
    "\n",
    "You completed the first two steps in the previous labs.\n",
    "\n",
    "In this lab we will walk-through the reminder of the deployment workflow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK Version: 1.0.2\n"
     ]
    }
   ],
   "source": [
    "# Verify AML SDK Installed\n",
    "# view version history at https://pypi.org/project/azureml-sdk/#history \n",
    "import azureml.core\n",
    "print(\"SDK Version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /data/home/demouser/notebooks/MTC_AzureAILabs/ML-AML-Walkthrough/aml_config/config.json\n",
      "jkamlworkshop\n",
      "jkamlworkshop\n",
      "southcentralus\n",
      "952a710c-8d9c-40c1-9fec-f752138cc0b3\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "# Read the workspace config from file\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the model from AML Model Registry.\n",
    "\n",
    "Download the model registered in the previous step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: AutoML5178497cbbest\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "# Download the model to a local directory\n",
    "model_name = 'propensity_to_buy_predictor'\n",
    "model_path = Model.get_model_path(model_name, _workspace=ws)\n",
    "\n",
    "# Re-load the model\n",
    "model = pickle.load(open(os.path.join(model_path, model_name + '.pkl'), 'rb'))\n",
    "print(\"Loaded model from:\", os.path.join(model_path, model_name + '.pkl'))\n",
    "\n",
    "# Re-load the scaler\n",
    "scaler = pickle.load(open(os.path.join(model_path, scaler_name + '.pkl'),'rb'))\n",
    "print(\"Loaded scaler from:\", os.path.join(model_path, scaler_name + '.pkl'))\n",
    "\n",
    "# Run a quick test\n",
    "age = 60\n",
    "km = 40000\n",
    "\n",
    "scaled_input = scaler.transform([[age, km]])\n",
    "prediction = model.predict(scaled_input)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and deploy the container image encapsulating the model\n",
    "\n",
    "When you deploy a model using AML to either ACI or AKS, you are deploying a Docker container encapsulating a trained model, its dependencies, and a web services wrapper around the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create scoring script\n",
    "Create the scoring script, called score.py, used by the web service call to invoke the model.\n",
    "\n",
    "You must include two required functions in the scoring script:\n",
    "\n",
    "- The `init()` function, which loads the model into a global object. This function is run only once when the Docker container is started.\n",
    "\n",
    "- The `run(input_data)` function uses the model to predict a value based on the input data. Inputs and outputs to the run typically use JSON for serialization and de-serialization, but other formats can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model \n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from azureml.core import Run\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.run import Run\n",
    "from azureml.core.experiment import Experiment\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "def init():\n",
    "    try:\n",
    "        # One-time initialization of predictive model and scaler\n",
    "        from azureml.core.model import Model\n",
    "        \n",
    "        global model   \n",
    "\n",
    "        model_name = '<<modelid>>'\n",
    "        model_path = Model.get_model_path(model_name, _workspace=ws)\n",
    "        model = pickle.load(open(model_path, 'rb'))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print('Exception during init: ', str(e))\n",
    "\n",
    "def run(input_json):     \n",
    "    try:\n",
    "        inputs = json.loads(input_json)\n",
    "\n",
    "        #Get the scored result\n",
    "        prediction = json.dumps(model.predict(inputs).tolist())\n",
    "\n",
    "    except Exception as e:\n",
    "        prediction = str(e)\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substitute the actual model ID in the script file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model_name = 'propensity_to_buy_predictor'\n",
    "model = Model(ws, name=model_name)\n",
    "script_file_name = 'score.py'\n",
    "\n",
    "with open(script_file_name, 'r') as cefr:\n",
    "    content = cefr.read()\n",
    "    \n",
    "with open(script_file_name, 'w') as cefw:\n",
    "    cefw.write(content.replace('<<modelid>>', model.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the updated script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import json\n",
      "import os\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn import linear_model \n",
      "from sklearn.externals import joblib\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.model_selection import train_test_split\n",
      "from azureml.core import Run\n",
      "from azureml.core import Workspace\n",
      "from azureml.core.run import Run\n",
      "from azureml.core.experiment import Experiment\n",
      "import pickle\n",
      "from sklearn.externals import joblib\n",
      "\n",
      "def init():\n",
      "    try:\n",
      "        # One-time initialization of predictive model and scaler\n",
      "        from azureml.core.model import Model\n",
      "        \n",
      "        global model   \n",
      "\n",
      "        model_name = 'propensity_to_buy_predictor'\n",
      "        model_path = Model.get_model_path(model_name, _workspace=ws)\n",
      "        model = pickle.load(open(model_path, 'rb'))\n",
      "        \n",
      "    except Exception as e:\n",
      "        print('Exception during init: ', str(e))\n",
      "\n",
      "def run(input_json):     \n",
      "    try:\n",
      "        inputs = json.loads(input_json)\n",
      "\n",
      "        #Get the scored result\n",
      "        prediction = json.dumps(model.predict(inputs).tolist())\n",
      "\n",
      "    except Exception as e:\n",
      "        prediction = str(e)\n",
      "    return prediction\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"score.py\",\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------ Sandbox ---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model \n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from azureml.core import Run\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.run import Run\n",
    "from azureml.core.experiment import Experiment\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "def init():\n",
    "    try:\n",
    "        # One-time initialization of predictive model and scaler\n",
    "        from azureml.core.model import Model\n",
    "        \n",
    "        global model   \n",
    "\n",
    "        model_name = 'propensity_to_buy_predictor'\n",
    "        model_path = Model.get_model_path(model_name, _workspace=ws)\n",
    "        #model = pickle.load(open(model_path, 'rb'))\n",
    "        print(model_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print('Exception during init: ', str(e))\n",
    "\n",
    "def run(input_json):     \n",
    "    try:\n",
    "        inputs = json.loads(input_json)\n",
    "\n",
    "        #Get the scored result\n",
    "        prediction = json.dumps(model.predict(inputs).tolist())\n",
    "\n",
    "    except Exception as e:\n",
    "        prediction = str(e)\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml-models/propensity_to_buy_predictor/6/model.pkl\n"
     ]
    }
   ],
   "source": [
    "init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'propensity_to_buy_predictor'\n",
    "model_path = Model.get_model_path(model_name, _workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator StandardScaler from version 0.20.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.20.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator Pipeline from version 0.20.2 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------- Sandbox --------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Conda dependencies environment file.\n",
    "\n",
    "Next, create an environment file that specifies the script's package dependencies. This file is used to ensure that all of those dependencies are installed in the Docker image. \n",
    "\n",
    "To ensure the consistency of the prediction results with the training results, the AML SDK dependency versions used by the scoring environment needs to be the same as in the environment that was used to train the model.\n",
    "\n",
    "The SDK dependency versions used to train the model can be retrieved from the run history.\n",
    "\n",
    "You need to replace the values in `experiment_name`  with the name of your experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'azureml-train-automl': '1.0.6', 'azureml-telemetry': '1.0.6', 'azureml-explain-model': '1.0.6', 'azureml-defaults': '1.0.6', 'azureml-dataprep': '1.0.6', 'azureml-dataprep-native': '11.2.0', 'azureml-core': '1.0.6'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "\n",
    "# Retrieve training run record\n",
    "experiment_name = 'propensity_to_buy_classifier_automatedml'\n",
    "run_id = model.tags['RunID'] \n",
    "\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "automl_run = AutoMLRun(experiment = experiment, run_id = run_id)\n",
    "\n",
    "# Retrieve SDK dependencies. \n",
    "dependencies = automl_run.get_run_sdk_dependencies(iteration = 0, check_versions=False)\n",
    "print(dependencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create conda environment file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies()\n",
    "#myenv.add_channel('defaults')\n",
    "#myenv.add_pip_package(\"azureml-sdk[notebooks,automl]==\" + sdk_version)\n",
    "#myenv.remove_pip_package('azureml-defaults')\n",
    "for package, version in dependencies.items():\n",
    "    myenv.add_pip_package('{}=={}'.format(package, version))\n",
    "    \n",
    "with open(\"mydeployenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "#mycondaenv = CondaDependencies.create(conda_packages=['scikit-learn','numpy','pandas'])\n",
    "mycondaenv = CondaDependencies.create()\n",
    "\n",
    "with open(\"mydeployenv.yml\",\"w\") as f:\n",
    "    f.write(mycondaenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the content of 'yml' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "  - azureml-defaults==1.0.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"mydeployenv.yml\",\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create docker image for deployment\n",
    "\n",
    "To create a Container Image, you need four things: the model metadata (as retrieved from Model Registry), the scoring script file, the runtime configuration (defining whether Python or PySpark should be used) and the Conda Dependencies file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running...................\n",
      "SucceededImage creation operation finished for image propensity-to-buy-classifier:4, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.image import ContainerImage, Image\n",
    "\n",
    "# Define runtime\n",
    "runtime = \"python\" \n",
    "\n",
    "# Define scoring script\n",
    "driver_file = \"score.py\"\n",
    "\n",
    "# Define conda dependencies\n",
    "conda_file = \"mydeployenv.yml\"\n",
    "\n",
    "# configure the image\n",
    "image_config = ContainerImage.image_configuration(execution_script=driver_file, \n",
    "                                                  runtime=runtime, \n",
    "                                                  conda_file=conda_file,\n",
    "                                                  description=\"Image for propensity to buy predictor\",\n",
    "                                                  tags={\"Classifier\": \"AutomatedML\"})\n",
    "\n",
    "image = Image.create(name = \"propensity-to-buy-classifier\",\n",
    "                     models = [model],\n",
    "                     image_config = image_config, \n",
    "                     workspace = ws)\n",
    "\n",
    "image.wait_for_creation(show_output = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the container image to ACI\n",
    "\n",
    "With the Container Image  in hand, you are almost ready to deploy to ACI. The next step is to define the size of the VM that ACI will use to run your Container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "aci_config = AciWebservice.deploy_configuration(\n",
    "    cpu_cores = 1, \n",
    "    memory_gb = 1, \n",
    "    tags = {'name':'Azure ML ACI'}, \n",
    "    description = 'This is a deployment of the propensity to buy predictor.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you can deploy the image to the webservice to ACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "service_name = \"usedcarsmlservice-aci\"\n",
    "print(\"Deploying: \", service_name)\n",
    "aci_service = Webservice.deploy_from_image(deployment_config = aci_config,\n",
    "                                           image = image,\n",
    "                                           name = service_name,\n",
    "                                           workspace = ws)\n",
    "aci_service.wait_for_deployment(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the service\n",
    "\n",
    "Once the webservice deployment completes, you can use the returned webservice object to invoke the webservice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "age = 60\n",
    "km = 40000\n",
    "test_data  = json.dumps([[age,km]])\n",
    "test_data\n",
    "result = aci_service.run(input_data=test_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the container image to AKS\n",
    "\n",
    "Once you are familiar with the process for deploying a webservice to ACI, you will find the process for deploying to AKS to be similar with one additional step that creates the AKS cluster first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provision an AKS cluster \n",
    "\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "\n",
    "# Use the default configuration, overriding the default location to a known region that supports AKS\n",
    "prov_config = AksCompute.provisioning_configuration(location='westus2')\n",
    "\n",
    "aks_name = 'aks-cluster01' \n",
    "\n",
    "# Create the cluster\n",
    "aks_target = ComputeTarget.create(workspace = ws, \n",
    "                                  name = aks_name, \n",
    "                                  provisioning_configuration = prov_config)\n",
    "\n",
    "\n",
    "# Wait for cluster to be ready\n",
    "aks_target.wait_for_completion(show_output = True)\n",
    "print(aks_target.provisioning_state)\n",
    "print(aks_target.provisioning_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your AKS cluster ready, now you can deploy your webservice. Once again, you need to provide a configuration for the size of resources allocated from the AKS cluster to run instances of your Container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the web service configuration (using defaults)\n",
    "aks_config = AksWebservice.deploy_configuration()\n",
    "\n",
    "aks_service_name ='usedcarsmlservice-aks'\n",
    "\n",
    "aks_service = Webservice.deploy_from_image(\n",
    "  workspace=ws, \n",
    "  name=aks_service_name, \n",
    "  image = image,\n",
    "  deployment_target=aks_target\n",
    "  )\n",
    "\n",
    "\n",
    "aks_service.wait_for_deployment(show_output = True)\n",
    "print(aks_service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the service\n",
    "As before, you can use the webservice object returned by the deploy_from_model method to invoke your deployed webservice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "age = 60\n",
    "km = 40000\n",
    "test_data  = json.dumps([[age,km]])\n",
    "test_data\n",
    "result = aks_service.run(input_data=test_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Make sure to remove ACI and AKS deployments. Use Azure Portal to remove *Deployments* and *AKS Compute*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
